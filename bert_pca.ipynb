{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# All skl imports go here\n",
    "from sklearn import tree   # Decision Trees\n",
    "from sklearn import svm    # svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn import metrics\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"data/training_bert.csv\")\n",
    "test_data = pd.read_csv(\"data/test_bert.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation_bert.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [x for x in train_data if x.startswith(\"_e\")]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])\n",
    "\n",
    "# These are used to run val and test for Neural Nets\n",
    "X_val_test = pd.concat([X_val, X_test])\n",
    "Y_val_test = pd.concat([Y_val, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pre-processing PCA on the training set\n",
    "def perform_pca(dataset, target_variance):\n",
    "    pca = PCA(n_components= target_variance)\n",
    "\n",
    "    # Need to standardize the data frirst\n",
    "    standardized = (dataset - dataset.mean(axis=0)) / dataset.std(axis = 0)\n",
    "\n",
    "    pca.fit(X=standardized)\n",
    "    dataset_reduced = pca.fit_transform(X=standardized)\n",
    "\n",
    "    return pca, dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 components for training\n"
     ]
    }
   ],
   "source": [
    "TARGET_EXPLAINED_VARIANCE = 100\n",
    "\n",
    "pca_train, X_train_reduced = perform_pca(X_train, TARGET_EXPLAINED_VARIANCE)\n",
    "X_val_reduced = pca_train.transform(X_val)\n",
    "X_test_reduced = pca_train.transform(X_test)\n",
    "\n",
    "print(f\"{pca_train.n_components_} components for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 components for training\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames with reduced data and corresponding target labels\n",
    "columns_reduced = [f\"e_{i}\" for i in range(pca_train.n_components_)]\n",
    "df_train = pd.DataFrame(data={'label': Y_train, **dict(zip(columns_reduced, X_train_reduced.T))})\n",
    "df_val = pd.DataFrame(data={'label': Y_val, **dict(zip(columns_reduced, X_val_reduced.T))})\n",
    "df_test = pd.DataFrame(data={'label': Y_test, **dict(zip(columns_reduced, X_test_reduced.T))})\n",
    "\n",
    "# Print the number of components for training\n",
    "print(f\"{pca_train.n_components_} components for training\")\n",
    "\n",
    "# Save the DataFrames into CSV files\n",
    "df_train.to_csv('data/training_bert_reduced.csv', index=False)\n",
    "df_val.to_csv('data/validation_bert_reduced.csv', index=False)\n",
    "df_test.to_csv('data/test_bert_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
