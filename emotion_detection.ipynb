{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# All skl imports go here\n",
    "from sklearn import tree   # Decision Trees\n",
    "from sklearn import svm    # svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn import metrics\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"data/training_labse.csv\")\n",
    "test_data = pd.read_csv(\"data/test_labse.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation_labse.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [x for x in train_data if x.startswith(\"_e\")]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])\n",
    "\n",
    "# These are used to run val and test for Neural Nets\n",
    "X_val_test = pd.concat([X_val, X_test])\n",
    "Y_val_test = pd.concat([Y_val, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pre-processing PCA on the training set\n",
    "def perform_pca(dataset, target_variance):\n",
    "    pca = PCA(n_components= target_variance)\n",
    "\n",
    "    # Need to standardize the data frirst\n",
    "    standardized = (dataset - dataset.mean(axis=0)) / dataset.std(axis = 0)\n",
    "\n",
    "    pca.fit(X=standardized)\n",
    "    dataset_reduced = pca.fit_transform(X=standardized)\n",
    "\n",
    "    return pca, dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 components for training\n"
     ]
    }
   ],
   "source": [
    "TARGET_EXPLAINED_VARIANCE = 0.999999\n",
    "\n",
    "pca_train, X_train_reduced = perform_pca(X_train, TARGET_EXPLAINED_VARIANCE)\n",
    "X_val_reduced = pca_train.transform(X_val)\n",
    "X_test_redced = pca_train.transform(X_test)\n",
    "X_train_val_reduced = pca_train.transform(X_train_val)\n",
    "X_val_test_reduced = pca_train.transform(X_val_test)\n",
    "\n",
    "print(f\"{pca_train.n_components_} components for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[814.69738354 546.67104552 528.87107772 502.73663688 482.85581159\n",
      " 466.81679316 442.68152216 430.42286856 422.01865155 411.74269209\n",
      " 409.00392128 403.11215021 394.65041765 391.32999999 389.2364008\n",
      " 385.37578798 367.76396378 362.41597822 361.82567218 358.29425668\n",
      " 355.38206026 353.86319187 348.04244124 345.94840278 340.53904307\n",
      " 338.4970436  332.97550988 330.00885012 325.1969818  322.61594639\n",
      " 319.9033563  317.19004342 310.80980127 310.52524287 308.87651055\n",
      " 304.5386695  302.95481421 298.49463695 296.36065653 294.7988591\n",
      " 292.43711462 291.62820072 288.36843427 287.10120672 285.6328987\n",
      " 281.21760348 277.99769435 276.41506484 275.11401628 273.96804488\n",
      " 270.88290065 268.23564673 265.77070274 265.22002507 263.61160194\n",
      " 261.06462165 259.77284801 258.86329056 255.94540799 254.62433271\n",
      " 253.8495155  251.35305198 248.41280944 247.29636352 247.25089942\n",
      " 244.54703063 242.8967489  241.01063318 240.20377196 239.08196251\n",
      " 237.54106365 236.08777325 234.61402917 232.57704573 231.81800438\n",
      " 230.92240035 228.63229429 227.9639835  226.00601892 224.40782752\n",
      " 222.09213388 221.1106321  219.85144287 219.36327309 218.90235077\n",
      " 216.75583762 215.54027352 213.75759632 213.30421307 211.56508658\n",
      " 210.39067674 208.80856036 206.9514139  205.37518006 204.72070112\n",
      " 202.76586059 201.51841013 200.78137729 199.73359871 198.73620192\n",
      " 198.31863587 196.94467783 196.59175847 195.73037809 193.84241352\n",
      " 192.04812638 191.12944548 189.6424143  187.59878324 186.27587708\n",
      " 184.90194632 184.08249675 183.78332768 182.40751175 181.44884519\n",
      " 178.44429567 177.86478672 175.91863008 175.3177598  174.17842522\n",
      " 173.6239511  172.95591172 171.59504243 169.6841818  169.42888774\n",
      " 168.85956091 167.9221965  166.32575489 165.68799758 164.68981656\n",
      " 163.97298731 162.73283139 161.40546936 160.5513395  159.69967208\n",
      " 158.8988459  157.91222679 157.34453262 155.61024736 155.27695809\n",
      " 153.71741332 151.94427421 150.77293887 149.70617565 149.16369174\n",
      " 148.35358115 147.20144978 146.01575242 143.77493977 143.00845135\n",
      " 142.52617246 140.75487364 139.97799783 138.74595533 138.28214598\n",
      " 136.71778484 135.06208848 134.87272591 133.65098282 132.62906676\n",
      " 130.22197754 129.93746945 128.8449706  126.62194876 126.07718686\n",
      " 125.87965147 124.8347231  121.14779639 120.8901147  120.30264748\n",
      " 118.82409992 117.8066724  117.0178354  114.628014   114.02082008\n",
      " 111.54806008 110.39167574 108.42392695 106.45426421 105.31774923\n",
      " 104.86046943 102.10498906  99.68820816  97.03049902  95.35319222\n",
      "  93.81048797  92.57381346  90.7632944   87.64080267  85.96931293\n",
      "  82.52415382  81.83476517  80.3110975   78.30187574  77.2343254\n",
      "  74.52517132  72.78641172  71.65269963  69.0081953   68.14297926\n",
      "  66.91572922  65.25959342  62.77201266  62.56910284  60.64331563\n",
      "  60.11526733  59.48113341  58.32885019  57.80376017  57.2536628\n",
      "  55.95166663  55.72253888  55.43371325  55.28982552  54.91235313\n",
      "  54.01141847  53.33343292  52.58798142  51.99037358  51.55416176\n",
      "  51.14954924  50.93872768  50.11043665  50.09902766  49.84578559\n",
      "  49.38222123  49.17098752  48.91853631  48.42441593  48.15725051\n",
      "  47.9850868   47.61570668  47.33914665  47.12914852  46.95669394\n",
      "  46.49555515  46.21570683  46.11114446  45.83336764  45.66608663\n",
      "  45.13772784  45.09202783  44.8894758   44.70443978  44.39601185\n",
      "  44.25208015  43.96486351  43.86276043  43.44053387  43.35401138\n",
      "  43.18702051  42.96732034  42.81151585  42.77473982  42.32261605\n",
      "  42.26753162  42.04731277  41.93471916  41.76531895  41.65909208\n",
      "  41.34165807  41.08991266  40.98728236  40.88401319  40.59893854\n",
      "  40.50879806  40.34621366  40.17517836  40.08497273  39.93978433\n",
      "  39.5916079   39.43460185  39.36594611  39.13843774  39.10947331\n",
      "  38.81918601  38.56188563  38.46228797  38.40139452  38.26516591\n",
      "  38.15270409  38.00487351  37.96368775  37.88971872  37.61232939\n",
      "  37.45537994  37.34634973  37.13763146  36.87182326  36.76161925\n",
      "  36.68160604  36.60105077  36.47882837  36.44724943  36.37212225\n",
      "  36.21137132  36.06942295  35.98541532  35.89542765  35.81019568\n",
      "  35.62394743  35.55436633  35.38317493  35.3572271   35.0885694\n",
      "  35.03622965  34.96230437  34.85082147  34.7281911   34.6181545\n",
      "  34.5441667   34.54258456  34.31114348  34.25002578  34.15698894\n",
      "  34.06689463  34.03215765  33.96077375  33.69890175  33.68950873\n",
      "  33.51220112  33.4086364   33.33664821  33.25857402  33.23975742\n",
      "  33.11139653  33.00182557  32.93223265  32.81407611  32.7103427\n",
      "  32.55833596  32.55404017  32.40599264  32.23395382  32.20993005\n",
      "  32.15710531  31.93135531  31.86585128  31.82149704  31.6655519\n",
      "  31.5294142   31.47593587  31.39426095  31.35962522  31.27993719\n",
      "  31.2661927   31.13737218  31.10913614  31.03894562  30.92488626\n",
      "  30.80092655  30.72865282  30.65261667  30.58481126  30.54847497\n",
      "  30.46462529  30.39782525  30.35550959  30.19431328  30.15851984\n",
      "  30.05756245  30.03787809  29.92688625  29.83080358  29.78990968\n",
      "  29.72025351  29.61121098  29.52888461  29.46799482  29.40502829\n",
      "  29.35509888  29.30996095  29.25540278  29.16858258  29.07709427\n",
      "  29.01447391  28.95433933  28.87176328  28.77521777  28.70963639\n",
      "  28.66521511  28.52055286  28.47532054  28.42291673  28.3696646\n",
      "  28.22881746  28.1777724   28.10682221  28.03198676  27.98513062\n",
      "  27.92080467  27.85304913  27.8429871   27.7719934   27.69498591\n",
      "  27.67077336  27.54883707  27.52262656  27.49321434  27.41881636\n",
      "  27.37004291  27.33091487  27.29778846  27.27782771  27.17220682\n",
      "  27.09535964  27.01464994  26.97642012  26.92071113  26.8178343\n",
      "  26.74567068  26.68317083  26.64712611  26.626202    26.52796517\n",
      "  26.47519643  26.42700947  26.34675271  26.27647288  26.26631881\n",
      "  26.21799851  26.14500984  26.0659673   26.05937897  25.95846448\n",
      "  25.93819086  25.84846719  25.81174529  25.76043603  25.73628157\n",
      "  25.70985703  25.63131958  25.58242775  25.55890125  25.48736921\n",
      "  25.45161614  25.39409008  25.36649889  25.32121749  25.26817522\n",
      "  25.24232296  25.14196568  25.08882397  25.0529939   24.98405349\n",
      "  24.93192428  24.84263108  24.78569429  24.72636833  24.66643053\n",
      "  24.64806518  24.63153953  24.58689509  24.52727911  24.49011517\n",
      "  24.47260338  24.42284681  24.38434565  24.26796585  24.25240996\n",
      "  24.24220129  24.18941764  24.15522055  24.12796986  24.06315937\n",
      "  24.02992781  24.00806235  23.93871015  23.91041905  23.89087083\n",
      "  23.83360025  23.79561142  23.76587633  23.69151566  23.64803486\n",
      "  23.6355529   23.58287021  23.57145928  23.52915392  23.51630436\n",
      "  23.4562425   23.40123858  23.35497808  23.34879458  23.26705608\n",
      "  23.24598244  23.23510901  23.1943152   23.16626443  23.08754308\n",
      "  23.07269448  23.00231702  22.97941239  22.94841146  22.94077398\n",
      "  22.87341824  22.80728033  22.79470986  22.78443292  22.72824371\n",
      "  22.70706694  22.68958059  22.65088632  22.62495835  22.57718956\n",
      "  22.5402147   22.50419019  22.43652077  22.41666716  22.37448255\n",
      "  22.34972136  22.28506962  22.27724644  22.24212314  22.20280949\n",
      "  22.17160602  22.1189139   22.08444621  22.05809044  21.9916395\n",
      "  21.95776199  21.91990599  21.88496596  21.87554564  21.85454979\n",
      "  21.81593472  21.78265706  21.75484183  21.68913135  21.65426826\n",
      "  21.63781355  21.62525314  21.5949572   21.52351062  21.47728779\n",
      "  21.43403756  21.38818631  21.37119363  21.36033419  21.31262908\n",
      "  21.30227768  21.26599268  21.22312258  21.19068294  21.17187761\n",
      "  21.13929752  21.10798266  21.07048719  21.039717    21.00350709\n",
      "  20.96996466  20.93357175  20.87991653  20.82879439  20.80481761\n",
      "  20.78478941  20.74593367  20.73515443  20.70874978  20.66633078\n",
      "  20.65267431  20.62396909  20.57142558  20.50846786  20.50202228\n",
      "  20.49079633  20.4669697   20.43651184  20.40664761  20.39386426\n",
      "  20.35549526  20.3295855   20.27331406  20.24767748  20.23952201\n",
      "  20.20942929  20.17398134  20.15685358  20.13152004  20.08275812\n",
      "  20.06784718  20.01178315  19.99163486  19.97187861  19.94729646\n",
      "  19.9405966   19.87744434  19.86341087  19.84253883  19.78989659\n",
      "  19.7537081   19.71825103  19.68796563  19.64902445  19.62122531\n",
      "  19.60048199  19.56488843  19.53346765  19.49964531  19.49539784\n",
      "  19.46868012  19.43729195  19.42439423  19.41671802  19.37239639\n",
      "  19.34135106  19.33186409  19.28009057  19.2577316   19.24777879\n",
      "  19.19579604  19.18263907  19.16504547  19.12204194  19.10386517\n",
      "  19.07513726  19.04902126  19.00662678  18.98678125  18.94192203\n",
      "  18.93030394  18.89876029  18.86362981  18.83971335  18.82395873\n",
      "  18.77691114  18.75247534  18.74367746  18.72217021  18.70612789\n",
      "  18.68840219  18.64834024  18.6028969   18.5611124   18.53561955\n",
      "  18.51767969  18.49010813  18.46009676  18.43189138  18.41500902\n",
      "  18.39557845  18.3862714   18.36491648  18.32490306  18.29752898\n",
      "  18.26605244  18.21816976  18.20363509  18.1898153   18.14695668\n",
      "  18.11075179  18.08549334  18.06927579  18.06356752  18.03796279\n",
      "  18.01029127  17.9858899   17.95969748  17.94184119  17.91621463\n",
      "  17.89669424  17.84316062  17.82755681  17.78841256  17.75869092\n",
      "  17.71261779  17.70652065  17.67989939  17.65517656  17.63157266\n",
      "  17.60926295  17.57442167  17.55561707  17.55053537  17.49909734\n",
      "  17.48506152  17.45020692  17.42137826  17.40443186  17.37670378\n",
      "  17.35664663  17.32622352  17.29927236  17.2905311   17.26943717\n",
      "  17.24508073  17.22995744  17.1892527   17.16569446  17.12168224\n",
      "  17.10315457  17.08284932  17.0673009   17.02770474  17.0005096\n",
      "  16.99294759  16.98316168  16.92484604  16.89741496  16.87597413\n",
      "  16.85991084  16.85550022  16.82358688  16.79637111  16.77285034\n",
      "  16.72305944  16.6948874   16.67664009  16.66526006  16.63403658\n",
      "  16.59207344  16.57906839  16.56925909  16.51819847  16.50228717\n",
      "  16.49101844  16.45553367  16.42471298  16.4132497   16.38604358\n",
      "  16.34779832  16.30160394  16.25771646  16.234261    16.23305178\n",
      "  16.18450284  16.15449262  16.11262136  16.09429922  16.07492795\n",
      "  16.04321145  16.01765003  15.99333778  15.97374261  15.96101407\n",
      "  15.92588975  15.87604055  15.83859155  15.82140126  15.80487386\n",
      "  15.76685124  15.71529651  15.68920335  15.66032862  15.63100044\n",
      "  15.59068849  15.57735272  15.54369989  15.50030459  15.48448882\n",
      "  15.46723964  15.43107795  15.3957593   15.33778024  15.31498388\n",
      "  15.28231169  15.2224185   15.1984766   15.17962939  15.13792977\n",
      "  15.09218409  15.01937756  14.94842136  14.94178575  14.7987222\n",
      "  14.77517499  14.69281029  14.43504012]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pca_train.singular_values_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unreduced = X_train.to_numpy()\n",
    "X_val_unreduced = X_val.to_numpy()\n",
    "X_test_unreduced = X_test.to_numpy()\n",
    "X_train_val_unreduced = X_train_val.to_numpy()\n",
    "X_val_test_unreduced = X_val_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_folds_x_val(model, X, y, k =  5): \n",
    "    results = cross_validate(model, X, y, cv=k, scoring=[\"accuracy\"])\n",
    "    mean_accuracy = results['test_accuracy'].mean()\n",
    "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "    return mean_accuracy, \n",
    "\n",
    "def get_cmat(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return confusion_matrix(y, y_pred, normalize=\"pred\")\n",
    "\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return accuracy_score(y, y_pred), f1_score(y, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchHPO(model, search_space):\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                                param_grid=search_space,\n",
    "                                scoring='accuracy',\n",
    "                                cv=5,\n",
    "                                verbose=3,\n",
    "                                error_score='raise',\n",
    "                                n_jobs=-1,  # -1 means max amount\n",
    "                                )\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = tree.DecisionTreeClassifier(\n",
    "    criterion ='entropy', \n",
    "    splitter = 'best',\n",
    "    max_depth = 256, \n",
    "    max_features = 'sqrt',\n",
    "    max_leaf_nodes = 80,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', \n",
    "# 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']\n",
    "dt_search_space = {\n",
    "    # 'ccp_alpha':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_leaf_nodes':[71, 72, 73, 74, 75, 76, 77, 78, 79, 80], \n",
    "    # 'min_impurity_decrease':[1.0, 0.5, 1.5, 2.0], # float\n",
    "    # 'min_weight_fraction_leaf':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_depth':[255, 256, 257, 258, 259, 260], \n",
    "    # 'max_features':[\"log2\", \"sqrt\"], \n",
    "    # 'min_samples_leaf':[0.1, 0.2, 0.4, 0.5], \n",
    "    # 'min_samples_split':[0.1, 0.2, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "model_dt = decision_tree_model.fit(X_train, Y_train)\n",
    "\n",
    "gridsearch_dt = gridSearchHPO(model=model_dt, search_space=dt_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(gridsearch_dt.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_dt.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_model = KNeighborsClassifier(\n",
    "    n_jobs=-1,\n",
    "    weights=\"uniform\",\n",
    "    algorithm=\"ball_tree\",\n",
    "    metric=\"cityblock\",\n",
    "    leaf_size=2,\n",
    "    n_neighbors=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search_space = {\n",
    "    \"n_neighbors\": [60],\n",
    "    # \"weights\": ['uniform', 'distance'], # Uniform\n",
    "    # \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'], # ball tree\n",
    "    # \"metric\": ['cityblock', 'euclidean', 'l1', 'l2', 'manhattan', 'minkowski'], # city block\n",
    "    # \"leaf_size\": [2], # 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = k_nearest_model.fit(X_train, Y_train)\n",
    "\n",
    "gridsearch_knn = gridSearchHPO(model=model_knn, search_space=knn_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Score: 0.5619375\n",
      "Best params: {'n_neighbors': 60}\n"
     ]
    }
   ],
   "source": [
    "gridsearch_knn.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best Score: {}\".format(gridsearch_knn.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_knn.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(max_iter=-1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_classifier.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# k_folds_x_val(svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search_space={\n",
    "    'C': [1],\n",
    "    'kernel': ['poly'], # poly - 'rbf', 'linear', 'sigmoid' \n",
    "    'degree': [3],  # 3\n",
    "    'gamma': ['scale'], #'auto',  1, 0.1, 0.01, 0.001, 0.0001, \n",
    "    'coef0': [0.1], \n",
    "    'shrinking': [True], \n",
    "    'probability': [False], \n",
    "    'tol': [0.1],  \n",
    "    'class_weight': [None], \n",
    "    'decision_function_shape': ['ovr'], # 'ovo'\n",
    "}\n",
    "\n",
    "gridsearch_svm = gridSearchHPO(svm_classifier, svm_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(gridsearch_svm.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_svm.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch specific constants\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.trainer import training_loop, evaluate\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_used = X_train_unreduced\n",
    "X_test_used = X_test_unreduced\n",
    "X_val_used = X_val_unreduced\n",
    "X_train_val_used = X_train_val_unreduced\n",
    "X_val_test_used = X_val_test_unreduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier([], 'relu', solver=\"adam\")\n",
    "mlp.fit(X_train_used, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds_x_val(mlp, X_train_val_used, Y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = get_cmat(mlp, X_val_test_used, Y_val_test)\n",
    "print(get_metrics(mlp, X_val_test_used, Y_val_test))\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.trainer import training_loop, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pytorch specifically we should load data to the provided dataloader and dataset classes. \n",
    "# This handles the batching for us.\n",
    "\n",
    "pt_train_set = TensorDataset(torch.Tensor(X_train_used), torch.Tensor(Y_train.to_numpy()).long())\n",
    "pt_val_set = TensorDataset(torch.Tensor(X_val_used), torch.Tensor(Y_val.to_numpy()).long())\n",
    "pt_test_set = TensorDataset(torch.Tensor(X_test_used), torch.Tensor(Y_test.to_numpy()).long())\n",
    "pt_val_test_set = TensorDataset(torch.Tensor(X_val_test_used), torch.Tensor(Y_val_test.to_numpy()).long())\n",
    "\n",
    "pt_train_loader = DataLoader(\n",
    "                    dataset=pt_train_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_val_loader = DataLoader(\n",
    "                    dataset=pt_val_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_test_loader = DataLoader(\n",
    "                    dataset=pt_test_set, \n",
    "                    batch_size=1, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "\n",
    "pt_val_test_loader = DataLoader(\n",
    "                    dataset=pt_val_test_set, \n",
    "                    batch_size=1, \n",
    "                    shuffle=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network\n",
    "mlp = NeuralNetwork(X_train_reduced.shape[1], [], NUM_CLASSES)\n",
    "\n",
    "training_loop(mlp, pt_train_loader, pt_val_loader, 200, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=pt_val_test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [2, 3, 4, 5, 6, 8, 10, 12, 16, 32, 48, 64, 128, 256, 512]\n",
    "dbi_score_list = []\n",
    "for k in k_list:\n",
    "    # Create a KMeans model with the specified number of clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "\n",
    "    # Fit the K-Means model to your data\n",
    "    kmeans.fit(X_train)\n",
    "\n",
    "    # Get the cluster assignments for each data point\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Calculate the Davies-Bouldin Index (DBI) to evaluate the clustering\n",
    "    dbi_score = davies_bouldin_score(X_train, labels)\n",
    "    dbi_score_list.append((k, dbi_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dbi = min(dbi_score_list, key = lambda i : i[1])\n",
    "print(f\"Highest DBI Score: K={best_dbi[0]}, DBI={best_dbi[1]}\")\n",
    "\n",
    "kmeans_best = KMeans(n_clusters=best_dbi[0], random_state=42, n_init='auto')\n",
    "\n",
    "kmeans_best.fit(X_test)\n",
    "preds = kmeans_best.predict(X_test)\n",
    "cmat = confusion_matrix(Y_test, preds)\n",
    "\n",
    "plt.bar([x for (x,y) in dbi_score_list], [y for (x,y) in dbi_score_list])\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
