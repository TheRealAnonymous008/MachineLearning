{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# All skl imports go here\n",
    "from sklearn import tree   # Decision Trees\n",
    "from sklearn import svm    # svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import sklearn as skl\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "from neuralnet import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"training_labse.csv\")\n",
    "test_data = pd.read_csv(\"test_labse.csv\")\n",
    "validation_data = pd.read_csv(\"validation_labse.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [x for x in train_data if x.startswith(\"_e\")]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pre-processing PCA on the training set\n",
    "TARGET_EXPLAINED_VARIANCE = 0.95 \n",
    "\n",
    "def perform_pca(dataset):\n",
    "    pca = PCA(n_components= TARGET_EXPLAINED_VARIANCE)\n",
    "\n",
    "    # Need to standardize the data frirst\n",
    "    standardized = (dataset - dataset.mean(axis=0)) / dataset.std(axis = 0)\n",
    "\n",
    "    pca.fit(X=standardized)\n",
    "    dataset_reduced = pca.fit_transform(X=standardized)\n",
    "\n",
    "    return pca, dataset_reduced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train, X_train_reduced = perform_pca(X_train)\n",
    "pca_tran_val, X_train_val_reduced = perform_pca(X_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_folds_x_val(model): \n",
    "    cumulative_accuracy = 0\n",
    "    cumulative_kappa = 0\n",
    "\n",
    "    k_folds = KFold(n_splits=10)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(k_folds.split(X_train_val_reduced, Y_train_val)):\n",
    "        model.fit(X_train_val_reduced[train_index], Y_train_val.iloc[train_index])\n",
    "        \n",
    "        Y_pred = model.predict(X_train_val_reduced[test_index])\n",
    "        Y_true = Y_train_val.iloc[test_index]\n",
    "        # Add all metrics here\n",
    "\n",
    "        cumulative_accuracy += metrics.accuracy_score(Y_true, Y_pred)\n",
    "        cumulative_kappa += metrics.cohen_kappa_score(Y_true, Y_pred)\n",
    "\n",
    "    folds = k_folds.get_n_splits()\n",
    "    print(f\"Performed {folds}-fold cross validation\")\n",
    "    print(f\"Average accuracy {cumulative_accuracy / folds}\")\n",
    "    print(f\"Average Kappa {cumulative_kappa / folds}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(model):\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    return metrics.accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "def gridSearchHPO(model, search_space):\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                                param_grid=search_space,\n",
    "                                scoring='accuracy',\n",
    "                                cv=5,\n",
    "                                verbose=3,\n",
    "                                error_score='raise',\n",
    "                                n_jobs=-1,  # -1 means max amount\n",
    "                                )\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', \n",
    "    splitter = 'best',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', \n",
    "# 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']\n",
    "dt_search_space = {\n",
    "    'ccp_alpha':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_leaf_nodes':[2, 16, 32, 64], \n",
    "    'min_impurity_decrease':[1.0, 0.5, 1.5, 2.0], # float\n",
    "    'min_weight_fraction_leaf':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_depth':[2, 8, 16, 32], \n",
    "    'max_features':[\"log2\", \"sqrt\"], \n",
    "    'min_samples_leaf':[0.1, 0.2, 0.4, 0.5], \n",
    "    'min_samples_split':[0.1, 0.2, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "gridsearch_dt = gridSearchHPO(model=decision_tree_model, search_space=dt_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32768 candidates, totalling 163840 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "             estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;), n_jobs=-1,\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [2, 8, 16, 32],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 16, 32, 64],\n",
       "                         &#x27;min_impurity_decrease&#x27;: [1.0, 0.5, 1.5, 2.0],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;min_samples_split&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.1, 0.2, 0.4, 0.5]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "             estimator=DecisionTreeClassifier(criterion=&#x27;entropy&#x27;), n_jobs=-1,\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [2, 8, 16, 32],\n",
       "                         &#x27;max_features&#x27;: [&#x27;log2&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [2, 16, 32, 64],\n",
       "                         &#x27;min_impurity_decrease&#x27;: [1.0, 0.5, 1.5, 2.0],\n",
       "                         &#x27;min_samples_leaf&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;min_samples_split&#x27;: [0.1, 0.2, 0.4, 0.5],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.1, 0.2, 0.4, 0.5]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=DecisionTreeClassifier(criterion='entropy'), n_jobs=-1,\n",
       "             param_grid={'ccp_alpha': [0.1, 0.2, 0.4, 0.5],\n",
       "                         'max_depth': [2, 8, 16, 32],\n",
       "                         'max_features': ['log2', 'sqrt'],\n",
       "                         'max_leaf_nodes': [2, 16, 32, 64],\n",
       "                         'min_impurity_decrease': [1.0, 0.5, 1.5, 2.0],\n",
       "                         'min_samples_leaf': [0.1, 0.2, 0.4, 0.5],\n",
       "                         'min_samples_split': [0.1, 0.2, 0.4, 0.5],\n",
       "                         'min_weight_fraction_leaf': [0.1, 0.2, 0.4, 0.5]},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.335125\n",
      "Best params: {'ccp_alpha': 0.1, 'max_depth': 2, 'max_features': 'log2', 'max_leaf_nodes': 2, 'min_impurity_decrease': 1.0, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'min_weight_fraction_leaf': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: {}\".format(gridsearch_dt.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_dt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.1, criterion=&#x27;entropy&#x27;, max_depth=2,\n",
       "                       max_features=&#x27;log2&#x27;, max_leaf_nodes=2,\n",
       "                       min_impurity_decrease=1.0, min_samples_leaf=0.1,\n",
       "                       min_samples_split=0.1, min_weight_fraction_leaf=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.1, criterion=&#x27;entropy&#x27;, max_depth=2,\n",
       "                       max_features=&#x27;log2&#x27;, max_leaf_nodes=2,\n",
       "                       min_impurity_decrease=1.0, min_samples_leaf=0.1,\n",
       "                       min_samples_split=0.1, min_weight_fraction_leaf=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.1, criterion='entropy', max_depth=2,\n",
       "                       max_features='log2', max_leaf_nodes=2,\n",
       "                       min_impurity_decrease=1.0, min_samples_leaf=0.1,\n",
       "                       min_samples_split=0.1, min_weight_fraction_leaf=0.1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_dt.best_estimator_\n",
    "gridsearch_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\techt\\Documents\\Programming\\MachineLearning\\emotion_detection.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/techt/Documents/Programming/MachineLearning/emotion_detection.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# find best model score\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/techt/Documents/Programming/MachineLearning/emotion_detection.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m gridsearch_dt\u001b[39m.\u001b[39;49mscore(X_train, Y_train)\n",
      "File \u001b[1;32mc:\\Users\\techt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:456\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the score on the given data, if the estimator has been refit.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \n\u001b[0;32m    435\u001b[0m \u001b[39mThis uses the score defined by ``scoring`` where provided, and the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[39m    ``best_estimator_.score`` method otherwise.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    455\u001b[0m _check_refit(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 456\u001b[0m check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscorer_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    459\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo score function explicitly defined, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand the estimator doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt provide one \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\techt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# find best model score\n",
    "gridsearch_dt.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model.fit(X_train_reduced, Y_train)\n",
    "tree.plot_tree(decision_tree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel='sigmoid') # 'precomputed', 'linear', 'poly', 'sigmoid', 'rbf'\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_classifier.fit(X_train_reduced, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "k_folds_x_val(svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_svm = gridSearchHPO(decision_tree_model, search_space={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch specific constants\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pytorch specifically we should load data to the provided dataloader and dataset classes. \n",
    "# This handles the batching for us.\n",
    "\n",
    "pt_train_set = TensorDataset(torch.Tensor(X_train_reduced), torch.Tensor(Y_train.to_numpy()).long())\n",
    "pt_val_set = TensorDataset(torch.Tensor(pca_train.transform(X_val)), torch.Tensor(Y_val.to_numpy()).long())\n",
    "pt_test_set = TensorDataset(torch.Tensor(pca_train.transform(X_test)), torch.Tensor(Y_test.to_numpy()).long())\n",
    "\n",
    "pt_train_loader = DataLoader(\n",
    "                    dataset=pt_train_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_val_loader = DataLoader(\n",
    "                    dataset=pt_val_set, \n",
    "                    batch_size=1, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_test_loader = DataLoader(\n",
    "                    dataset=pt_test_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: torch.nn.modules, dl: DataLoader, optimizer, loss_fn):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(dl):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        last_loss = loss.item()\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "def training_loop(model : torch.nn.Module, dl : DataLoader, epochs = 1):\n",
    "    optimizer = Adam(params=model.parameters(True), lr=LEARNING_RATE, betas=[0.9, 0.999])\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = train_one_epoch(model, dl, optimizer, loss_fn)\n",
    "\n",
    "        model.eval()\n",
    "        running_vloss = 0\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(pt_val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / len(pt_val_loader)\n",
    "        print(f\"train_loss = {train_loss :.4f}, val_loss = {avg_vloss :.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network\n",
    "mlp = NeuralNetwork(X_train_reduced.shape[1], [], NUM_CLASSES)\n",
    "\n",
    "training_loop(mlp, pt_train_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Only Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_test = decision_tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add stuff for running the test set on the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
