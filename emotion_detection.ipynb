{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# All skl imports go here\n",
    "from sklearn import tree   # Decision Trees\n",
    "from sklearn import svm    # svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn import metrics\n",
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"data/training_labse.csv\")\n",
    "test_data = pd.read_csv(\"data/test_labse.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation_labse.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [x for x in train_data if x.startswith(\"_e\")]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])\n",
    "\n",
    "# These are used to run val and test for Neural Nets\n",
    "X_val_test = pd.concat([X_val, X_test])\n",
    "Y_val_test = pd.concat([Y_val, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pre-processing PCA on the training set\n",
    "def perform_pca(dataset, target_variance):\n",
    "    pca = PCA(n_components= target_variance)\n",
    "\n",
    "    # Need to standardize the data frirst\n",
    "    standardized = (dataset - dataset.mean(axis=0)) / dataset.std(axis = 0)\n",
    "\n",
    "    pca.fit(X=standardized)\n",
    "    dataset_reduced = pca.fit_transform(X=standardized)\n",
    "\n",
    "    return pca, dataset_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 components for training\n"
     ]
    }
   ],
   "source": [
    "TARGET_EXPLAINED_VARIANCE = 0.999999\n",
    "\n",
    "pca_train, X_train_reduced = perform_pca(X_train, TARGET_EXPLAINED_VARIANCE)\n",
    "X_val_reduced = pca_train.transform(X_val)\n",
    "X_test_redced = pca_train.transform(X_test)\n",
    "X_train_val_reduced = pca_train.transform(X_train_val)\n",
    "X_val_test_reduced = pca_train.transform(X_val_test)\n",
    "\n",
    "print(f\"{pca_train.n_components_} components for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unreduced = X_train.to_numpy()\n",
    "X_val_unreduced = X_val.to_numpy()\n",
    "X_test_unreduced = X_test.to_numpy()\n",
    "X_train_val_unreduced = X_train_val.to_numpy()\n",
    "X_val_test_unreduced = X_val_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_used = X_train_unreduced\n",
    "X_val_used = X_val_unreduced\n",
    "X_test_used = X_test_unreduced\n",
    "X_train_val_used = X_train_val_unreduced \n",
    "X_val_test_used = X_val_test_unreduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature selector \n",
    "\n",
    "def forward_select(model, X, y, k): \n",
    "    sfs = SequentialFeatureSelector(estimator=model, n_features_to_select=k)\n",
    "    sfs.fit(X, y)\n",
    "    return sfs.get_feature_names_out(), sfs.transform(X)\n",
    "\n",
    "def forward_select_and_fit(model, X_train, Y_train, k, X_test, Y_test):\n",
    "    model : tree.DecisionTreeClassifier = skl.base.clone(model)\n",
    "    _, Xt = forward_select(model, X_train, Y_train, k)\n",
    "    model.fit(Xt, Y_train)\n",
    "\n",
    "    # TODO: Run tests here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def k_folds_x_val(model, X, y, k =  5): \n",
    "    results = cross_validate(model, X, y, cv=k, scoring=[\"accuracy\"])\n",
    "    mean_accuracy = results['test_accuracy'].mean()\n",
    "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "    return mean_accuracy, \n",
    "\n",
    "def get_cmat(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return confusion_matrix(y, y_pred, normalize=\"pred\")\n",
    "\n",
    "def get_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return accuracy_score(y, y_pred), f1_score(y, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchHPO(model, search_space):\n",
    "    grid_search = GridSearchCV(estimator=model,\n",
    "                                param_grid=search_space,\n",
    "                                scoring='accuracy',\n",
    "                                cv=5,\n",
    "                                verbose=3,\n",
    "                                error_score='raise',\n",
    "                                n_jobs=-1,  # -1 means max amount\n",
    "                                )\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = tree.DecisionTreeClassifier(\n",
    "    criterion ='entropy', \n",
    "    splitter = 'best',\n",
    "    max_depth = 256, \n",
    "    max_features = 'sqrt',\n",
    "    max_leaf_nodes = 80,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', \n",
    "# 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']\n",
    "dt_search_space = {\n",
    "    # 'ccp_alpha':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_leaf_nodes':[71, 72, 73, 74, 75, 76, 77, 78, 79, 80], \n",
    "    # 'min_impurity_decrease':[1.0, 0.5, 1.5, 2.0], # float\n",
    "    # 'min_weight_fraction_leaf':[0.1, 0.2, 0.4, 0.5],\n",
    "    'max_depth':[255, 256, 257, 258, 259, 260], \n",
    "    # 'max_features':[\"log2\", \"sqrt\"], \n",
    "    # 'min_samples_leaf':[0.1, 0.2, 0.4, 0.5], \n",
    "    # 'min_samples_split':[0.1, 0.2, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "model_dt = decision_tree_model.fit(X_train_used, Y_train)\n",
    "\n",
    "gridsearch_dt = gridSearchHPO(model=model_dt, search_space=dt_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_dt.fit(X_train_used, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(gridsearch_dt.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_dt.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Feature Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joaquin\\Desktop\\LaSalle\\MACLEARN\\MachineLearning\\emotion_detection.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/LaSalle/MACLEARN/MachineLearning/emotion_detection.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m decision_tree_model_reduced : tree\u001b[39m.\u001b[39mDecisionTreeClassifier \u001b[39m=\u001b[39m skl\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mclone(decision_tree_model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/LaSalle/MACLEARN/MachineLearning/emotion_detection.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Xt \u001b[39m=\u001b[39m forward_select(decision_tree_model_reduced, X_train_val_used, Y_train_val, \u001b[39m30\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/LaSalle/MACLEARN/MachineLearning/emotion_detection.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m decision_tree_model_reduced\u001b[39m.\u001b[39;49mfit(Xt, Y_train_val)\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:186\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    184\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    185\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    187\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    190\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_X_params:\n\u001b[0;32m    578\u001b[0m     check_X_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 579\u001b[0m X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_X_params)\n\u001b[0;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m check_y_params:\n\u001b[0;32m    581\u001b[0m     check_y_params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdefault_check_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "decision_tree_model_reduced : tree.DecisionTreeClassifier = skl.base.clone(decision_tree_model)\n",
    "Xt = forward_select(decision_tree_model_reduced, X_train_val_used, Y_train_val, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_model = KNeighborsClassifier(\n",
    "    n_jobs=-1,\n",
    "    weights=\"uniform\",\n",
    "    algorithm=\"ball_tree\",\n",
    "    metric=\"cityblock\",\n",
    "    leaf_size=2,\n",
    "    n_neighbors=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_search_space = {\n",
    "    \"n_neighbors\": [60],\n",
    "    # \"weights\": ['uniform', 'distance'], # Uniform\n",
    "    # \"algorithm\": ['auto', 'ball_tree', 'kd_tree', 'brute'], # ball tree\n",
    "    # \"metric\": ['cityblock', 'euclidean', 'l1', 'l2', 'manhattan', 'minkowski'], # city block\n",
    "    # \"leaf_size\": [2], # 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = k_nearest_model.fit(X_train, Y_train)\n",
    "\n",
    "gridsearch_knn = gridSearchHPO(model=model_knn, search_space=knn_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Score: 0.5619375\n",
      "Best params: {'n_neighbors': 60}\n"
     ]
    }
   ],
   "source": [
    "gridsearch_knn.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best Score: {}\".format(gridsearch_knn.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_knn.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With feature selection\n",
    "\n",
    "forward_select_and_fit(model_knn, X_train_val_used, Y_train_val, 30, X_test_used, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(max_iter=-1)\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_classifier.fit(X_train, Y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "# k_folds_x_val(svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_search_space={\n",
    "    'C': [1],\n",
    "    'kernel': ['poly'], # poly - 'rbf', 'linear', 'sigmoid' \n",
    "    'degree': [3],  # 3\n",
    "    'gamma': ['scale'], #'auto',  1, 0.1, 0.01, 0.001, 0.0001, \n",
    "    'coef0': [0.1], \n",
    "    'shrinking': [True], \n",
    "    'probability': [False], \n",
    "    'tol': [0.1],  \n",
    "    'class_weight': [None], \n",
    "    'decision_function_shape': ['ovr'], # 'ovo'\n",
    "}\n",
    "\n",
    "gridsearch_svm = gridSearchHPO(svm_classifier, svm_search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score: {}\".format(gridsearch_svm.best_score_))\n",
    "print(\"Best params: {}\".format(gridsearch_svm.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With forward selection \n",
    "\n",
    "forward_select_and_fit(svm_classifier, X_train_val_used, Y_train_val, 30, X_test_used, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch specific constants\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.trainer import training_loop, evaluate\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier([], 'relu', solver=\"adam\")\n",
    "mlp.fit(X_train_used, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds_x_val(mlp, X_train_val_used, Y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = get_cmat(mlp, X_val_test_used, Y_val_test)\n",
    "print(get_metrics(mlp, X_val_test_used, Y_val_test))\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With feature selection\n",
    "forward_select_and_fit(mlp, X_train_val_used, Y_train_val, 30, X_test_used, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.trainer import training_loop, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pytorch specifically we should load data to the provided dataloader and dataset classes. \n",
    "# This handles the batching for us.\n",
    "\n",
    "pt_train_set = TensorDataset(torch.Tensor(X_train_used), torch.Tensor(Y_train.to_numpy()).long())\n",
    "pt_val_set = TensorDataset(torch.Tensor(X_val_used), torch.Tensor(Y_val.to_numpy()).long())\n",
    "pt_test_set = TensorDataset(torch.Tensor(X_test_used), torch.Tensor(Y_test.to_numpy()).long())\n",
    "pt_val_test_set = TensorDataset(torch.Tensor(X_val_test_used), torch.Tensor(Y_val_test.to_numpy()).long())\n",
    "\n",
    "pt_train_loader = DataLoader(\n",
    "                    dataset=pt_train_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_val_loader = DataLoader(\n",
    "                    dataset=pt_val_set, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "pt_test_loader = DataLoader(\n",
    "                    dataset=pt_test_set, \n",
    "                    batch_size=1, \n",
    "                    shuffle=True,\n",
    "                )\n",
    "\n",
    "pt_val_test_loader = DataLoader(\n",
    "                    dataset=pt_val_test_set, \n",
    "                    batch_size=1, \n",
    "                    shuffle=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network\n",
    "mlp = NeuralNetwork(X_train_reduced.shape[1], [], NUM_CLASSES)\n",
    "\n",
    "training_loop(mlp, pt_train_loader, pt_val_loader, 200, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=pt_val_test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
