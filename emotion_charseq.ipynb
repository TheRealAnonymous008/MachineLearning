{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]\n",
    "WEIGHTS = torch.tensor([0.00287505, 0.00246512, 0.01015641, 0.00615233, 0.00702346, 0.02318034])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"data/training.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [\"text\"]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])\n",
    "\n",
    "# These are used to run val and test for Neural Nets\n",
    "X_val_test = pd.concat([X_val, X_test])\n",
    "Y_val_test = pd.concat([Y_val, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "X_train_maxtoks = X_train['text'].str.len().max()\n",
    "X_test_maxtoks = X_test['text'].str.len().max()\n",
    "X_val_maxtoks = X_val['text'].str.len().max() \n",
    "\n",
    "max_toks = max(X_train_maxtoks, X_test_maxtoks, X_val_maxtoks)\n",
    "print(max_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch specific constants\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from extractors.chartok import  CharTokenDataset\n",
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.rnn import LSTMNetwork\n",
    "from utils.transformer import TransformerEncoder\n",
    "from utils.trainer import training_loop, evaluate\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard 1 Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because an MLP operates on fixed size inputs, we will use the entire fixed size input for this\n",
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 14.1319, val_loss = 10.9809\n",
      "Epoch 2\n",
      "train_loss = 6.5794, val_loss = 9.5080\n",
      "Epoch 3\n",
      "train_loss = 8.4462, val_loss = 8.2256\n",
      "Epoch 4\n",
      "train_loss = 7.7316, val_loss = 6.9677\n",
      "Epoch 5\n",
      "train_loss = 6.8705, val_loss = 6.1499\n",
      "Epoch 6\n",
      "train_loss = 4.3087, val_loss = 5.1636\n",
      "Epoch 7\n",
      "train_loss = 3.0715, val_loss = 4.5402\n",
      "Epoch 8\n",
      "train_loss = 4.3688, val_loss = 3.9496\n",
      "Epoch 9\n",
      "train_loss = 4.2144, val_loss = 3.4908\n",
      "Epoch 10\n",
      "train_loss = 3.4534, val_loss = 3.1620\n",
      "Epoch 11\n",
      "train_loss = 2.4173, val_loss = 2.8750\n",
      "Epoch 12\n",
      "train_loss = 1.7483, val_loss = 2.6542\n",
      "Epoch 13\n",
      "train_loss = 2.5290, val_loss = 2.4934\n",
      "Epoch 14\n",
      "train_loss = 2.4047, val_loss = 2.3615\n",
      "Epoch 15\n",
      "train_loss = 3.1587, val_loss = 2.2878\n",
      "Epoch 16\n",
      "train_loss = 2.4034, val_loss = 2.1799\n",
      "Epoch 17\n",
      "train_loss = 1.6722, val_loss = 2.1088\n",
      "Epoch 18\n",
      "train_loss = 2.1270, val_loss = 2.0980\n",
      "Epoch 19\n",
      "train_loss = 1.7642, val_loss = 2.0686\n",
      "Epoch 20\n",
      "train_loss = 1.9087, val_loss = 2.0157\n",
      "Epoch 21\n",
      "train_loss = 2.0510, val_loss = 1.9927\n",
      "Epoch 22\n",
      "train_loss = 2.1266, val_loss = 1.9184\n",
      "Epoch 23\n",
      "train_loss = 1.8509, val_loss = 1.9300\n",
      "Epoch 24\n",
      "train_loss = 1.7056, val_loss = 1.8526\n",
      "Epoch 25\n",
      "train_loss = 1.9040, val_loss = 1.8429\n",
      "Epoch 26\n",
      "train_loss = 2.0186, val_loss = 1.8358\n",
      "Epoch 27\n",
      "train_loss = 1.8547, val_loss = 1.8869\n",
      "Epoch 28\n",
      "train_loss = 1.7964, val_loss = 1.9363\n",
      "Epoch 29\n",
      "train_loss = 1.5315, val_loss = 1.8085\n",
      "Epoch 30\n",
      "train_loss = 1.3817, val_loss = 1.8654\n",
      "Epoch 31\n",
      "train_loss = 1.7832, val_loss = 1.8657\n",
      "Epoch 32\n",
      "train_loss = 1.7152, val_loss = 1.7789\n",
      "Epoch 33\n",
      "train_loss = 1.6424, val_loss = 1.8108\n",
      "Epoch 34\n",
      "train_loss = 2.0119, val_loss = 1.9209\n",
      "Epoch 35\n",
      "train_loss = 1.7473, val_loss = 1.7781\n",
      "Epoch 36\n",
      "train_loss = 1.7767, val_loss = 1.7548\n",
      "Epoch 37\n",
      "train_loss = 2.2158, val_loss = 1.7580\n",
      "Epoch 38\n",
      "train_loss = 1.7131, val_loss = 1.7937\n",
      "Epoch 39\n",
      "train_loss = 1.6774, val_loss = 1.7509\n",
      "Epoch 40\n",
      "train_loss = 1.4807, val_loss = 1.7811\n",
      "Epoch 41\n",
      "train_loss = 1.8380, val_loss = 1.7608\n",
      "Epoch 42\n",
      "train_loss = 1.3609, val_loss = 1.7620\n",
      "Epoch 43\n",
      "train_loss = 1.6269, val_loss = 1.7727\n",
      "Epoch 44\n",
      "train_loss = 1.6277, val_loss = 1.7738\n",
      "Epoch 45\n",
      "train_loss = 1.8689, val_loss = 1.9156\n",
      "Epoch 46\n",
      "train_loss = 1.6783, val_loss = 1.8260\n",
      "Epoch 47\n",
      "train_loss = 1.7618, val_loss = 1.7909\n",
      "Epoch 48\n",
      "train_loss = 1.8196, val_loss = 1.7382\n",
      "Epoch 49\n",
      "train_loss = 1.8044, val_loss = 1.7209\n",
      "Epoch 50\n",
      "train_loss = 1.4748, val_loss = 1.8793\n",
      "Epoch 51\n",
      "train_loss = 1.7007, val_loss = 1.7281\n"
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE, path=\"models/slpseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.5597\n",
      "accuracy = 0.3255\n",
      "f1 = 0.2454\n",
      "[[0.27750411 0.29680697 0.         0.125      0.4        0.        ]\n",
      " [0.34154351 0.34833091 0.         0.625      0.4        0.        ]\n",
      " [0.09031199 0.0754717  0.         0.         0.         0.        ]\n",
      " [0.15106732 0.13207547 0.         0.125      0.         0.        ]\n",
      " [0.11494253 0.11030479 0.         0.125      0.2        0.        ]\n",
      " [0.02463054 0.03701016 0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because an MLP operates on fixed size inputs, we will use the entire fixed size input for this\n",
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.8094, val_loss = 1.6573\n",
      "Epoch 2\n",
      "train_loss = 1.5916, val_loss = 1.6417\n",
      "Epoch 3\n",
      "train_loss = 1.9723, val_loss = 1.6161\n",
      "Epoch 4\n",
      "train_loss = 1.6197, val_loss = 1.6175\n",
      "Epoch 5\n",
      "train_loss = 1.6450, val_loss = 1.6062\n",
      "Epoch 6\n",
      "train_loss = 1.4792, val_loss = 1.5986\n",
      "Epoch 7\n",
      "train_loss = 1.5470, val_loss = 1.5908\n",
      "Epoch 8\n",
      "train_loss = 1.5290, val_loss = 1.5840\n",
      "Epoch 9\n",
      "train_loss = 1.6139, val_loss = 1.5859\n",
      "Epoch 10\n",
      "train_loss = 1.5240, val_loss = 1.5824\n",
      "Epoch 11\n",
      "train_loss = 1.6363, val_loss = 1.5814\n",
      "Epoch 12\n",
      "train_loss = 1.5971, val_loss = 1.5804\n",
      "Epoch 13\n",
      "train_loss = 1.6183, val_loss = 1.5810\n",
      "Epoch 14\n",
      "train_loss = 1.6104, val_loss = 1.5789\n",
      "Epoch 15\n",
      "train_loss = 1.6257, val_loss = 1.5820\n",
      "Epoch 16\n",
      "train_loss = 1.5896, val_loss = 1.5794\n",
      "Epoch 17\n",
      "train_loss = 1.4972, val_loss = 1.5807\n",
      "Epoch 18\n",
      "train_loss = 1.6194, val_loss = 1.5790\n",
      "Epoch 19\n",
      "train_loss = 1.4347, val_loss = 1.5831\n",
      "Epoch 20\n",
      "train_loss = 1.5140, val_loss = 1.5819\n",
      "Epoch 21\n",
      "train_loss = 1.6526, val_loss = 1.5789\n",
      "Epoch 22\n",
      "train_loss = 1.4735, val_loss = 1.5814\n",
      "Epoch 23\n",
      "train_loss = 1.6117, val_loss = 1.5815\n",
      "Epoch 24\n",
      "train_loss = 1.8094, val_loss = 1.5807\n",
      "Epoch 25\n",
      "train_loss = 1.6577, val_loss = 1.5809\n",
      "Epoch 26\n",
      "train_loss = 1.5207, val_loss = 1.5810\n",
      "Epoch 27\n",
      "train_loss = 1.5577, val_loss = 1.5801\n",
      "Epoch 28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joaquin\\Desktop\\LaSalle\\MACLEARN\\MachineLearning\\emotion_charseq.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/LaSalle/MACLEARN/MachineLearning/emotion_charseq.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mlp \u001b[39m=\u001b[39m NeuralNetwork(max_toks, [\u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m100\u001b[39m], NUM_CLASSES, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/LaSalle/MACLEARN/MachineLearning/emotion_charseq.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m training_loop(mlp, train_loader, val_loader, epochs\u001b[39m=\u001b[39;49mEPOCHS, learning_rate\u001b[39m=\u001b[39;49mLEARNING_RATE, path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodels/mlpseq\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\Desktop\\LaSalle\\MACLEARN\\MachineLearning\\utils\\trainer.py:49\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, train_dl, val_dl, epochs, learning_rate, weights, path, tol, min_epoch, is_seq)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 49\u001b[0m train_loss \u001b[39m=\u001b[39m train_one_epoch(model, train_dl, optimizer, loss_fn, is_seq)\n\u001b[0;32m     51\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     52\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\Desktop\\LaSalle\\MACLEARN\\MachineLearning\\utils\\trainer.py:31\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dl, optimizer, loss_fn, is_seq)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# Compute the loss and its gradients\u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[1;32m---> 31\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     33\u001b[0m \u001b[39m# Adjust learning weights\u001b[39;00m\n\u001b[0;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [100, 100, 100], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE, path=\"models/mlpseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.5655\n",
      "accuracy = 0.3370\n",
      "f1 = 0.2498\n",
      "[[0.29693487 0.28834356 0.         0.33333333 0.2        0.        ]\n",
      " [0.33333333 0.3524199  0.         0.16666667 0.6        0.        ]\n",
      " [0.07279693 0.08248125 0.         0.         0.         0.        ]\n",
      " [0.13601533 0.13769598 0.         0.33333333 0.         0.        ]\n",
      " [0.13409962 0.10497614 0.         0.         0.         0.        ]\n",
      " [0.02681992 0.03408316 0.         0.16666667 0.2        0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP With Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.8480, val_loss = 1.7948\n",
      "Epoch 2\n",
      "train_loss = 1.8218, val_loss = 1.7905\n",
      "Epoch 3\n",
      "train_loss = 1.7990, val_loss = 1.7903\n",
      "Epoch 4\n",
      "train_loss = 1.8236, val_loss = 1.7907\n",
      "Epoch 5\n",
      "train_loss = 1.8086, val_loss = 1.7910\n",
      "Epoch 6\n",
      "train_loss = 1.8081, val_loss = 1.7913\n",
      "Epoch 7\n",
      "train_loss = 1.7710, val_loss = 1.7918\n",
      "Epoch 8\n",
      "train_loss = 1.7972, val_loss = 1.7921\n",
      "Epoch 9\n",
      "train_loss = 1.7786, val_loss = 1.7915\n",
      "Epoch 10\n",
      "train_loss = 1.8080, val_loss = 1.7923\n",
      "Epoch 11\n",
      "train_loss = 1.7877, val_loss = 1.7914\n",
      "Epoch 12\n",
      "train_loss = 1.8164, val_loss = 1.7925\n",
      "Epoch 13\n",
      "train_loss = 1.7978, val_loss = 1.7925\n",
      "Epoch 14\n",
      "train_loss = 1.7928, val_loss = 1.7924\n",
      "Epoch 15\n",
      "train_loss = 1.7945, val_loss = 1.7932\n",
      "Epoch 16\n",
      "train_loss = 1.7733, val_loss = 1.7929\n",
      "Epoch 17\n",
      "train_loss = 1.7933, val_loss = 1.7928\n",
      "Epoch 18\n",
      "train_loss = 1.7930, val_loss = 1.7924\n",
      "Epoch 19\n",
      "train_loss = 1.7931, val_loss = 1.7931\n",
      "Epoch 20\n",
      "train_loss = 1.7798, val_loss = 1.7928\n",
      "Epoch 21\n",
      "train_loss = 1.7913, val_loss = 1.7927\n",
      "Epoch 22\n",
      "train_loss = 1.7728, val_loss = 1.7927\n",
      "Epoch 23\n",
      "train_loss = 1.8010, val_loss = 1.7922\n",
      "Epoch 24\n",
      "train_loss = 1.8063, val_loss = 1.7919\n",
      "Epoch 25\n",
      "train_loss = 1.7988, val_loss = 1.7925\n",
      "Epoch 26\n",
      "train_loss = 1.7797, val_loss = 1.7923\n",
      "Epoch 27\n",
      "train_loss = 1.7924, val_loss = 1.7922\n",
      "Epoch 28\n",
      "train_loss = 1.8131, val_loss = 1.7931\n",
      "Epoch 29\n",
      "train_loss = 1.7570, val_loss = 1.7923\n",
      "Epoch 30\n",
      "train_loss = 1.7884, val_loss = 1.7928\n",
      "Epoch 31\n",
      "train_loss = 1.7724, val_loss = 1.7929\n",
      "Epoch 32\n",
      "train_loss = 1.7798, val_loss = 1.7920\n",
      "Epoch 33\n",
      "train_loss = 1.8083, val_loss = 1.7924\n",
      "Epoch 34\n",
      "train_loss = 1.8076, val_loss = 1.7925\n",
      "Epoch 35\n",
      "train_loss = 1.7560, val_loss = 1.7923\n",
      "Epoch 36\n",
      "train_loss = 1.7987, val_loss = 1.7919\n",
      "Epoch 37\n",
      "train_loss = 1.7849, val_loss = 1.7924\n",
      "Epoch 38\n",
      "train_loss = 1.7539, val_loss = 1.7947\n",
      "Epoch 39\n",
      "train_loss = 1.8782, val_loss = 1.7918\n",
      "Epoch 40\n",
      "train_loss = 1.7861, val_loss = 1.7920\n",
      "Epoch 41\n",
      "train_loss = 1.7914, val_loss = 1.7925\n",
      "Epoch 42\n",
      "train_loss = 1.7790, val_loss = 1.7919\n",
      "Epoch 43\n",
      "train_loss = 1.7939, val_loss = 1.7918\n",
      "Epoch 44\n",
      "train_loss = 1.8351, val_loss = 1.7909\n",
      "Epoch 45\n",
      "train_loss = 1.7761, val_loss = 1.7918\n",
      "Epoch 46\n",
      "train_loss = 1.7578, val_loss = 1.7952\n",
      "Epoch 47\n",
      "train_loss = 1.7941, val_loss = 1.7923\n",
      "Epoch 48\n",
      "train_loss = 1.8642, val_loss = 1.7914\n",
      "Epoch 49\n",
      "train_loss = 1.7957, val_loss = 1.7921\n",
      "Epoch 50\n",
      "train_loss = 1.7948, val_loss = 1.7909\n",
      "Epoch 51\n",
      "train_loss = 1.8156, val_loss = 1.7918\n"
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [100, 100, 100], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=100, learning_rate=LEARNING_RATE, path=\"models/mlpseqwt\", weights=WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.7698\n",
      "accuracy = 0.2635\n",
      "f1 = 0.2607\n",
      "[[0.34782609 0.25952045 0.26666667 0.2754717  0.26582278 0.31707317]\n",
      " [0.33277592 0.35260931 0.36       0.38113208 0.33333333 0.29268293]\n",
      " [0.06521739 0.09308886 0.07333333 0.06792453 0.092827   0.07317073]\n",
      " [0.10200669 0.15937941 0.18666667 0.10188679 0.16455696 0.17073171]\n",
      " [0.10702341 0.10014104 0.08       0.1509434  0.13080169 0.14634146]\n",
      " [0.0451505  0.03526093 0.03333333 0.02264151 0.01265823 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks, dtype = torch.int32)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.7882, val_loss = 1.7931\n",
      "Epoch 2\n",
      "train_loss = 1.8260, val_loss = 1.7939\n",
      "Epoch 3\n",
      "train_loss = 1.7908, val_loss = 1.7924\n",
      "Epoch 4\n",
      "train_loss = 1.7708, val_loss = 1.7925\n",
      "Epoch 5\n",
      "train_loss = 1.7943, val_loss = 1.7918\n",
      "Epoch 6\n",
      "train_loss = 1.7822, val_loss = 1.7915\n",
      "Epoch 7\n",
      "train_loss = 1.8270, val_loss = 1.7942\n",
      "Epoch 8\n",
      "train_loss = 1.8130, val_loss = 1.7926\n",
      "Epoch 9\n",
      "train_loss = 1.7885, val_loss = 1.7944\n",
      "Epoch 10\n",
      "train_loss = 1.7661, val_loss = 1.7928\n",
      "Epoch 11\n",
      "train_loss = 1.7836, val_loss = 1.7929\n",
      "Epoch 12\n",
      "train_loss = 1.8205, val_loss = 1.7944\n",
      "Epoch 13\n",
      "train_loss = 1.8072, val_loss = 1.7950\n",
      "Epoch 14\n",
      "train_loss = 1.7822, val_loss = 1.7927\n",
      "Epoch 15\n",
      "train_loss = 1.8481, val_loss = 1.7922\n",
      "Epoch 16\n",
      "train_loss = 1.7848, val_loss = 1.7923\n",
      "Epoch 17\n",
      "train_loss = 1.7909, val_loss = 1.7921\n",
      "Epoch 18\n",
      "train_loss = 1.7669, val_loss = 1.7921\n",
      "Epoch 19\n",
      "train_loss = 1.8121, val_loss = 1.7944\n",
      "Epoch 20\n",
      "train_loss = 1.8022, val_loss = 1.7946\n",
      "Epoch 21\n",
      "train_loss = 1.7814, val_loss = 1.7928\n",
      "Epoch 22\n",
      "train_loss = 1.8101, val_loss = 1.7932\n",
      "Epoch 23\n",
      "train_loss = 1.7955, val_loss = 1.7938\n",
      "Epoch 24\n",
      "train_loss = 1.7893, val_loss = 1.7929\n",
      "Epoch 25\n",
      "train_loss = 1.7703, val_loss = 1.7935\n",
      "Epoch 26\n",
      "train_loss = 1.7854, val_loss = 1.7949\n",
      "Epoch 27\n",
      "train_loss = 1.7941, val_loss = 1.7937\n",
      "Epoch 28\n",
      "train_loss = 1.7610, val_loss = 1.7926\n",
      "Epoch 29\n",
      "train_loss = 1.7768, val_loss = 1.7938\n",
      "Epoch 30\n",
      "train_loss = 1.7967, val_loss = 1.7936\n",
      "Epoch 31\n",
      "train_loss = 1.7769, val_loss = 1.7949\n",
      "Epoch 32\n",
      "train_loss = 1.7818, val_loss = 1.7942\n",
      "Epoch 33\n",
      "train_loss = 1.7676, val_loss = 1.7932\n",
      "Epoch 34\n",
      "train_loss = 1.7922, val_loss = 1.7924\n",
      "Epoch 35\n",
      "train_loss = 1.7800, val_loss = 1.7919\n",
      "Epoch 36\n",
      "train_loss = 1.7930, val_loss = 1.7939\n",
      "Epoch 37\n",
      "train_loss = 1.7858, val_loss = 1.7926\n",
      "Epoch 38\n",
      "train_loss = 1.7957, val_loss = 1.7931\n",
      "Epoch 39\n",
      "train_loss = 1.7775, val_loss = 1.7917\n",
      "Epoch 40\n",
      "train_loss = 1.8126, val_loss = 1.7934\n",
      "Epoch 41\n",
      "train_loss = 1.8071, val_loss = 1.7919\n",
      "Epoch 42\n",
      "train_loss = 1.7778, val_loss = 1.7924\n",
      "Epoch 43\n",
      "train_loss = 1.7931, val_loss = 1.7915\n",
      "Epoch 44\n",
      "train_loss = 1.7919, val_loss = 1.7938\n",
      "Epoch 45\n",
      "train_loss = 1.7870, val_loss = 1.7934\n",
      "Epoch 46\n",
      "train_loss = 1.7648, val_loss = 1.7931\n",
      "Epoch 47\n",
      "train_loss = 1.7905, val_loss = 1.7940\n",
      "Epoch 48\n",
      "train_loss = 1.8029, val_loss = 1.7933\n",
      "Epoch 49\n",
      "train_loss = 1.7773, val_loss = 1.7930\n",
      "Epoch 50\n",
      "train_loss = 1.8369, val_loss = 1.7921\n",
      "Epoch 51\n",
      "train_loss = 1.7728, val_loss = 1.7931\n",
      "Epoch 52\n",
      "train_loss = 1.7935, val_loss = 1.7925\n",
      "Epoch 53\n",
      "train_loss = 1.7801, val_loss = 1.7912\n",
      "Epoch 54\n",
      "train_loss = 1.7860, val_loss = 1.7934\n",
      "Epoch 55\n",
      "train_loss = 1.8059, val_loss = 1.7926\n",
      "Epoch 56\n",
      "train_loss = 1.7772, val_loss = 1.7966\n",
      "Epoch 57\n",
      "train_loss = 1.8013, val_loss = 1.7939\n",
      "Epoch 58\n",
      "train_loss = 1.7798, val_loss = 1.7923\n",
      "Epoch 59\n",
      "train_loss = 1.7894, val_loss = 1.7928\n",
      "Epoch 60\n",
      "train_loss = 1.8154, val_loss = 1.7920\n",
      "Epoch 61\n",
      "train_loss = 1.7791, val_loss = 1.7922\n",
      "Epoch 62\n",
      "train_loss = 1.7827, val_loss = 1.7943\n",
      "Epoch 63\n",
      "train_loss = 1.7615, val_loss = 1.7931\n",
      "Epoch 64\n",
      "train_loss = 1.8020, val_loss = 1.7930\n",
      "Epoch 65\n",
      "train_loss = 1.7765, val_loss = 1.7938\n",
      "Epoch 66\n",
      "train_loss = 1.7891, val_loss = 1.7922\n",
      "Epoch 67\n",
      "train_loss = 1.8146, val_loss = 1.7938\n",
      "Epoch 68\n",
      "train_loss = 1.7884, val_loss = 1.7924\n",
      "Epoch 69\n",
      "train_loss = 1.8076, val_loss = 1.7925\n",
      "Epoch 70\n",
      "train_loss = 1.7894, val_loss = 1.7934\n",
      "Epoch 71\n",
      "train_loss = 1.7505, val_loss = 1.7937\n",
      "Epoch 72\n",
      "train_loss = 1.7834, val_loss = 1.7914\n",
      "Epoch 73\n",
      "train_loss = 1.7844, val_loss = 1.7901\n",
      "Epoch 74\n",
      "train_loss = 1.7817, val_loss = 1.7943\n",
      "Epoch 75\n",
      "train_loss = 1.7681, val_loss = 1.7941\n",
      "Epoch 76\n",
      "train_loss = 1.8093, val_loss = 1.7913\n",
      "Epoch 77\n",
      "train_loss = 1.7879, val_loss = 1.7943\n",
      "Epoch 78\n",
      "train_loss = 1.8003, val_loss = 1.7951\n",
      "Epoch 79\n",
      "train_loss = 1.8109, val_loss = 1.7933\n",
      "Epoch 80\n",
      "train_loss = 1.7960, val_loss = 1.7934\n",
      "Epoch 81\n",
      "train_loss = 1.8135, val_loss = 1.7943\n",
      "Epoch 82\n",
      "train_loss = 1.7778, val_loss = 1.7935\n",
      "Epoch 83\n",
      "train_loss = 1.7640, val_loss = 1.7923\n",
      "Epoch 84\n",
      "train_loss = 1.7934, val_loss = 1.7936\n",
      "Epoch 85\n",
      "train_loss = 1.7820, val_loss = 1.7910\n",
      "Epoch 86\n",
      "train_loss = 1.7904, val_loss = 1.7939\n",
      "Epoch 87\n",
      "train_loss = 1.8276, val_loss = 1.7926\n",
      "Epoch 88\n",
      "train_loss = 1.7819, val_loss = 1.7917\n",
      "Epoch 89\n",
      "train_loss = 1.7824, val_loss = 1.7921\n",
      "Epoch 90\n",
      "train_loss = 1.8103, val_loss = 1.7944\n",
      "Epoch 91\n",
      "train_loss = 1.7702, val_loss = 1.7912\n",
      "Epoch 92\n",
      "train_loss = 1.7634, val_loss = 1.7924\n",
      "Epoch 93\n",
      "train_loss = 1.7554, val_loss = 1.7930\n",
      "Epoch 94\n",
      "train_loss = 1.7951, val_loss = 1.7939\n",
      "Epoch 95\n",
      "train_loss = 1.7897, val_loss = 1.7931\n",
      "Epoch 96\n",
      "train_loss = 1.8017, val_loss = 1.7932\n",
      "Epoch 97\n",
      "train_loss = 1.7797, val_loss = 1.7916\n",
      "Epoch 98\n",
      "train_loss = 1.7759, val_loss = 1.7922\n",
      "Epoch 99\n",
      "train_loss = 1.7628, val_loss = 1.7924\n",
      "Epoch 100\n",
      "train_loss = 1.7546, val_loss = 1.7943\n",
      "Epoch 101\n",
      "train_loss = 1.7929, val_loss = 1.7918\n",
      "Epoch 102\n",
      "train_loss = 1.7991, val_loss = 1.7930\n",
      "Epoch 103\n",
      "train_loss = 1.7952, val_loss = 1.7939\n",
      "Epoch 104\n",
      "train_loss = 1.7881, val_loss = 1.7927\n",
      "Epoch 105\n",
      "train_loss = 1.8091, val_loss = 1.7923\n",
      "Epoch 106\n",
      "train_loss = 1.7964, val_loss = 1.7915\n",
      "Epoch 107\n",
      "train_loss = 1.7890, val_loss = 1.7934\n",
      "Epoch 108\n",
      "train_loss = 1.8025, val_loss = 1.7929\n",
      "Epoch 109\n",
      "train_loss = 1.8042, val_loss = 1.7941\n",
      "Epoch 110\n",
      "train_loss = 1.7770, val_loss = 1.7942\n",
      "Epoch 111\n",
      "train_loss = 1.7992, val_loss = 1.7928\n",
      "Epoch 112\n",
      "train_loss = 1.7876, val_loss = 1.7933\n",
      "Epoch 113\n",
      "train_loss = 1.8079, val_loss = 1.7924\n",
      "Epoch 114\n",
      "train_loss = 1.7750, val_loss = 1.7918\n",
      "Epoch 115\n",
      "train_loss = 1.7893, val_loss = 1.7955\n",
      "Epoch 116\n",
      "train_loss = 1.7877, val_loss = 1.7928\n",
      "Epoch 117\n",
      "train_loss = 1.7913, val_loss = 1.7945\n",
      "Epoch 118\n",
      "train_loss = 1.7950, val_loss = 1.7939\n",
      "Epoch 119\n",
      "train_loss = 1.7678, val_loss = 1.7925\n",
      "Epoch 120\n",
      "train_loss = 1.7920, val_loss = 1.7941\n",
      "Epoch 121\n",
      "train_loss = 1.7821, val_loss = 1.7918\n",
      "Epoch 122\n",
      "train_loss = 1.8031, val_loss = 1.7929\n",
      "Epoch 123\n",
      "train_loss = 1.7800, val_loss = 1.7931\n",
      "Epoch 124\n",
      "train_loss = 1.7880, val_loss = 1.7925\n",
      "Epoch 125\n",
      "train_loss = 1.8166, val_loss = 1.7956\n",
      "Epoch 126\n",
      "train_loss = 1.7574, val_loss = 1.7915\n",
      "Epoch 127\n",
      "train_loss = 1.8466, val_loss = 1.7948\n",
      "Epoch 128\n",
      "train_loss = 1.7685, val_loss = 1.7915\n",
      "Epoch 129\n",
      "train_loss = 1.8103, val_loss = 1.7922\n",
      "Epoch 130\n",
      "train_loss = 1.7665, val_loss = 1.7929\n",
      "Epoch 131\n",
      "train_loss = 1.7813, val_loss = 1.7918\n",
      "Epoch 132\n",
      "train_loss = 1.7692, val_loss = 1.7935\n",
      "Epoch 133\n",
      "train_loss = 1.7899, val_loss = 1.7949\n",
      "Epoch 134\n",
      "train_loss = 1.7802, val_loss = 1.7932\n",
      "Epoch 135\n",
      "train_loss = 1.7516, val_loss = 1.7921\n",
      "Epoch 136\n",
      "train_loss = 1.8051, val_loss = 1.7930\n",
      "Epoch 137\n",
      "train_loss = 1.7811, val_loss = 1.7942\n",
      "Epoch 138\n",
      "train_loss = 1.7888, val_loss = 1.7949\n",
      "Epoch 139\n",
      "train_loss = 1.7888, val_loss = 1.7945\n",
      "Epoch 140\n",
      "train_loss = 1.7555, val_loss = 1.7912\n",
      "Epoch 141\n",
      "train_loss = 1.7975, val_loss = 1.7949\n",
      "Epoch 142\n",
      "train_loss = 1.7703, val_loss = 1.7937\n",
      "Epoch 143\n",
      "train_loss = 1.7791, val_loss = 1.7930\n",
      "Epoch 144\n",
      "train_loss = 1.7737, val_loss = 1.7943\n",
      "Epoch 145\n",
      "train_loss = 1.7961, val_loss = 1.7935\n",
      "Epoch 146\n",
      "train_loss = 1.7828, val_loss = 1.7919\n",
      "Epoch 147\n",
      "train_loss = 1.7754, val_loss = 1.7941\n",
      "Epoch 148\n",
      "train_loss = 1.8056, val_loss = 1.7917\n",
      "Epoch 149\n",
      "train_loss = 1.7838, val_loss = 1.7926\n",
      "Epoch 150\n",
      "train_loss = 1.7604, val_loss = 1.7932\n",
      "Epoch 151\n",
      "train_loss = 1.7771, val_loss = 1.7935\n",
      "Epoch 152\n",
      "train_loss = 1.8009, val_loss = 1.7924\n",
      "Epoch 153\n",
      "train_loss = 1.7883, val_loss = 1.7932\n",
      "Epoch 154\n",
      "train_loss = 1.7863, val_loss = 1.7953\n",
      "Epoch 155\n",
      "train_loss = 1.7765, val_loss = 1.7924\n",
      "Epoch 156\n",
      "train_loss = 1.7774, val_loss = 1.7952\n",
      "Epoch 157\n",
      "train_loss = 1.7944, val_loss = 1.7960\n",
      "Epoch 158\n",
      "train_loss = 1.7825, val_loss = 1.7917\n",
      "Epoch 159\n",
      "train_loss = 1.7911, val_loss = 1.7942\n",
      "Epoch 160\n",
      "train_loss = 1.7590, val_loss = 1.7902\n",
      "Epoch 161\n",
      "train_loss = 1.8046, val_loss = 1.7954\n",
      "Epoch 162\n",
      "train_loss = 1.7696, val_loss = 1.7934\n",
      "Epoch 163\n",
      "train_loss = 1.7985, val_loss = 1.7940\n",
      "Epoch 164\n",
      "train_loss = 1.8071, val_loss = 1.7923\n",
      "Epoch 165\n",
      "train_loss = 1.7666, val_loss = 1.7938\n",
      "Epoch 166\n",
      "train_loss = 1.8173, val_loss = 1.7943\n",
      "Epoch 167\n",
      "train_loss = 1.8103, val_loss = 1.7927\n",
      "Epoch 168\n",
      "train_loss = 1.7763, val_loss = 1.7925\n",
      "Epoch 169\n",
      "train_loss = 1.7802, val_loss = 1.7927\n",
      "Epoch 170\n",
      "train_loss = 1.7863, val_loss = 1.7936\n",
      "Epoch 171\n",
      "train_loss = 1.7848, val_loss = 1.7946\n",
      "Epoch 172\n",
      "train_loss = 1.7727, val_loss = 1.7919\n",
      "Epoch 173\n",
      "train_loss = 1.8083, val_loss = 1.7950\n",
      "Epoch 174\n",
      "train_loss = 1.7774, val_loss = 1.7922\n",
      "Epoch 175\n",
      "train_loss = 1.7714, val_loss = 1.7940\n",
      "Epoch 176\n",
      "train_loss = 1.8155, val_loss = 1.7944\n",
      "Epoch 177\n",
      "train_loss = 1.7723, val_loss = 1.7913\n",
      "Epoch 178\n",
      "train_loss = 1.8021, val_loss = 1.7931\n",
      "Epoch 179\n",
      "train_loss = 1.8100, val_loss = 1.7917\n",
      "Epoch 180\n",
      "train_loss = 1.7842, val_loss = 1.7949\n",
      "Epoch 181\n",
      "train_loss = 1.7775, val_loss = 1.7926\n",
      "Epoch 182\n",
      "train_loss = 1.7934, val_loss = 1.7925\n",
      "Epoch 183\n",
      "train_loss = 1.7620, val_loss = 1.7931\n",
      "Epoch 184\n",
      "train_loss = 1.8084, val_loss = 1.7931\n",
      "Epoch 185\n",
      "train_loss = 1.7793, val_loss = 1.7944\n",
      "Epoch 186\n",
      "train_loss = 1.8265, val_loss = 1.7940\n",
      "Epoch 187\n",
      "train_loss = 1.8247, val_loss = 1.7940\n",
      "Epoch 188\n",
      "train_loss = 1.7859, val_loss = 1.7931\n",
      "Epoch 189\n",
      "train_loss = 1.7565, val_loss = 1.7944\n",
      "Epoch 190\n",
      "train_loss = 1.8045, val_loss = 1.7920\n",
      "Epoch 191\n",
      "train_loss = 1.7743, val_loss = 1.7919\n",
      "Epoch 192\n",
      "train_loss = 1.8072, val_loss = 1.7942\n",
      "Epoch 193\n",
      "train_loss = 1.8039, val_loss = 1.7940\n",
      "Epoch 194\n",
      "train_loss = 1.7786, val_loss = 1.7933\n",
      "Epoch 195\n",
      "train_loss = 1.7795, val_loss = 1.7943\n",
      "Epoch 196\n",
      "train_loss = 1.8060, val_loss = 1.7929\n",
      "Epoch 197\n",
      "train_loss = 1.7902, val_loss = 1.7934\n",
      "Epoch 198\n",
      "train_loss = 1.7782, val_loss = 1.7933\n",
      "Epoch 199\n",
      "train_loss = 1.7852, val_loss = 1.7939\n",
      "Epoch 200\n",
      "train_loss = 1.8264, val_loss = 1.7940\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMNetwork(40, 100, 10, NUM_CLASSES)\n",
    "training_loop(lstm, train_loader, val_loader, epochs=200, is_seq=True, learning_rate=LEARNING_RATE, path=\"models/lstmseq\", weights=WEIGHTS, min_epoch=200)\n",
    "torch.save(lstm.state_dict(), \"models/lstmseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.7578\n",
      "accuracy = 0.2540\n",
      "f1 = 0.2442\n",
      "[[0.30749682 0.28314239 0.25454545 0.30735931 0.24782609 0.32258065]\n",
      " [0.33036849 0.33224223 0.43636364 0.36363636 0.40869565 0.19354839]\n",
      " [0.07115629 0.09328969 0.06363636 0.07792208 0.0826087  0.06451613]\n",
      " [0.14358323 0.14075286 0.11818182 0.12554113 0.12608696 0.16129032]\n",
      " [0.11435832 0.11129296 0.10909091 0.09090909 0.11304348 0.22580645]\n",
      " [0.03303685 0.03927987 0.01818182 0.03463203 0.02173913 0.03225806]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=lstm, val_dl=test_loader, is_seq=True)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks, dtype = torch.int32)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.6508, val_loss = 1.6222\n",
      "Epoch 2\n",
      "train_loss = 1.5769, val_loss = 1.5946\n",
      "Epoch 3\n",
      "train_loss = 1.4551, val_loss = 1.5910\n",
      "Epoch 4\n",
      "train_loss = 1.5014, val_loss = 1.5814\n",
      "Epoch 5\n",
      "train_loss = 1.5917, val_loss = 1.5837\n",
      "Epoch 6\n",
      "train_loss = 1.6480, val_loss = 1.5811\n",
      "Epoch 7\n",
      "train_loss = 1.5471, val_loss = 1.5830\n",
      "Epoch 8\n",
      "train_loss = 1.6141, val_loss = 1.5803\n",
      "Epoch 9\n",
      "train_loss = 1.4598, val_loss = 1.5804\n",
      "Epoch 10\n",
      "train_loss = 1.5913, val_loss = 1.5794\n",
      "Epoch 11\n",
      "train_loss = 1.7146, val_loss = 1.5803\n",
      "Epoch 12\n",
      "train_loss = 1.6829, val_loss = 1.5799\n",
      "Epoch 13\n",
      "train_loss = 1.5592, val_loss = 1.5818\n",
      "Epoch 14\n",
      "train_loss = 1.5192, val_loss = 1.5815\n",
      "Epoch 15\n",
      "train_loss = 1.5419, val_loss = 1.5823\n",
      "Epoch 16\n",
      "train_loss = 1.6418, val_loss = 1.5798\n",
      "Epoch 17\n",
      "train_loss = 1.7238, val_loss = 1.5816\n",
      "Epoch 18\n",
      "train_loss = 1.4821, val_loss = 1.5809\n",
      "Epoch 19\n",
      "train_loss = 1.4655, val_loss = 1.5792\n",
      "Epoch 20\n",
      "train_loss = 1.4532, val_loss = 1.5812\n",
      "Epoch 21\n",
      "train_loss = 1.7097, val_loss = 1.5850\n",
      "Epoch 22\n",
      "train_loss = 1.7608, val_loss = 1.5828\n",
      "Epoch 23\n",
      "train_loss = 1.4823, val_loss = 1.5815\n",
      "Epoch 24\n",
      "train_loss = 1.6633, val_loss = 1.5805\n",
      "Epoch 25\n",
      "train_loss = 1.4823, val_loss = 1.5838\n",
      "Epoch 26\n",
      "train_loss = 1.6756, val_loss = 1.5822\n",
      "Epoch 27\n",
      "train_loss = 1.5750, val_loss = 1.5832\n",
      "Epoch 28\n",
      "train_loss = 1.5782, val_loss = 1.5809\n",
      "Epoch 29\n",
      "train_loss = 1.4437, val_loss = 1.5815\n",
      "Epoch 30\n",
      "train_loss = 1.6265, val_loss = 1.5794\n",
      "Epoch 31\n",
      "train_loss = 1.6524, val_loss = 1.5813\n",
      "Epoch 32\n",
      "train_loss = 1.6739, val_loss = 1.5811\n",
      "Epoch 33\n",
      "train_loss = 1.6333, val_loss = 1.5822\n",
      "Epoch 34\n",
      "train_loss = 1.6210, val_loss = 1.5837\n",
      "Epoch 35\n",
      "train_loss = 1.8544, val_loss = 1.5812\n",
      "Epoch 36\n",
      "train_loss = 1.8703, val_loss = 1.5823\n",
      "Epoch 37\n",
      "train_loss = 1.6136, val_loss = 1.5808\n",
      "Epoch 38\n",
      "train_loss = 1.6252, val_loss = 1.5813\n",
      "Epoch 39\n",
      "train_loss = 1.7460, val_loss = 1.5822\n",
      "Epoch 40\n",
      "train_loss = 1.5087, val_loss = 1.5813\n",
      "Epoch 41\n",
      "train_loss = 1.4266, val_loss = 1.5802\n",
      "Epoch 42\n",
      "train_loss = 1.5699, val_loss = 1.5827\n",
      "Epoch 43\n",
      "train_loss = 1.5683, val_loss = 1.5826\n",
      "Epoch 44\n",
      "train_loss = 1.5728, val_loss = 1.5818\n",
      "Epoch 45\n",
      "train_loss = 1.5962, val_loss = 1.5821\n",
      "Epoch 46\n",
      "train_loss = 1.7134, val_loss = 1.5836\n",
      "Epoch 47\n",
      "train_loss = 1.5971, val_loss = 1.5793\n",
      "Epoch 48\n",
      "train_loss = 1.4761, val_loss = 1.5798\n",
      "Epoch 49\n",
      "train_loss = 1.4280, val_loss = 1.5814\n",
      "Epoch 50\n",
      "train_loss = 1.4768, val_loss = 1.5827\n",
      "Epoch 51\n",
      "train_loss = 1.6281, val_loss = 1.5789\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerEncoder(max_toks, NUM_CLASSES, 10, 5, 4, ff=10, dropout=0.1)\n",
    "training_loop(transformer, train_loader,val_loader,  is_seq=True,  epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
    "torch.save(transformer.state_dict(), \"models/xformerseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.5590\n",
      "accuracy = 0.3295\n",
      "f1 = 0.2509\n",
      "[[0.28120063 0.29416112 0.         0.41666667 0.         0.        ]\n",
      " [0.34123223 0.35254989 0.         0.08333333 0.5        0.        ]\n",
      " [0.08530806 0.07612712 0.         0.16666667 0.         0.        ]\n",
      " [0.14691943 0.1322986  0.         0.25       0.         0.        ]\n",
      " [0.10900474 0.11308204 0.         0.08333333 0.5        0.        ]\n",
      " [0.03633491 0.03178123 0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=transformer, val_dl=test_loader, is_seq=True)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
