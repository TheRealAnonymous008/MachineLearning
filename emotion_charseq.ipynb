{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 6\n",
    "CLASSES = [\"sadnesss\", \"joy\", \"love\", \"anger\", \"fear\"]\n",
    "WEIGHTS = torch.tensor([0.00287505, 0.00246512, 0.01015641, 0.00615233, 0.00702346, 0.02318034])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "train_data = pd.read_csv(\"data/training.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "validation_data = pd.read_csv(\"data/validation.csv\")\n",
    "\n",
    "# Separate X's and y's from each other\n",
    "FEATURE_COLUMNS = [\"text\"]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "X_train = train_data[FEATURE_COLUMNS]\n",
    "Y_train = train_data[LABEL_COLUMN]\n",
    "\n",
    "X_test = test_data[FEATURE_COLUMNS]\n",
    "Y_test = test_data[LABEL_COLUMN]\n",
    "\n",
    "X_val = validation_data[FEATURE_COLUMNS]\n",
    "Y_val = validation_data[LABEL_COLUMN]\n",
    "\n",
    "# These are used to run cross validation\n",
    "X_train_val = pd.concat([X_train, X_val]) \n",
    "Y_train_val = pd.concat([Y_train, Y_test])\n",
    "\n",
    "# These are used to run val and test for Neural Nets\n",
    "X_val_test = pd.concat([X_val, X_test])\n",
    "Y_val_test = pd.concat([Y_val, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "X_train_maxtoks = X_train['text'].str.len().max()\n",
    "X_test_maxtoks = X_test['text'].str.len().max()\n",
    "X_val_maxtoks = X_val['text'].str.len().max() \n",
    "\n",
    "max_toks = max(X_train_maxtoks, X_test_maxtoks, X_val_maxtoks)\n",
    "print(max_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch specific constants\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from extractors.chartok import  CharTokenDataset\n",
    "from utils.neuralnet import NeuralNetwork\n",
    "from utils.rnn import LSTMNetwork\n",
    "from utils.transformer import TransformerEncoder\n",
    "from utils.trainer import training_loop, evaluate\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard 1 Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because an MLP operates on fixed size inputs, we will use the entire fixed size input for this\n",
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 9.2975, val_loss = 10.2098\n",
      "Epoch 2\n",
      "train_loss = 12.6134, val_loss = 8.7077\n",
      "Epoch 3\n",
      "train_loss = 10.5616, val_loss = 7.5655\n",
      "Epoch 4\n",
      "train_loss = 5.3264, val_loss = 6.4254\n",
      "Epoch 5\n",
      "train_loss = 6.3155, val_loss = 5.4205\n",
      "Epoch 6\n",
      "train_loss = 4.2532, val_loss = 4.7690\n",
      "Epoch 7\n",
      "train_loss = 2.9543, val_loss = 4.0090\n",
      "Epoch 8\n",
      "train_loss = 4.9168, val_loss = 3.7271\n",
      "Epoch 9\n",
      "train_loss = 3.6610, val_loss = 3.1578\n",
      "Epoch 10\n",
      "train_loss = 2.6208, val_loss = 2.8568\n",
      "Epoch 11\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE, path=\"models/slpseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.6553\n",
      "accuracy = 0.3445\n",
      "f1 = 0.2521\n",
      "[[0.32790698 0.28116883 0.11111111 0.23076923 0.42857143 0.        ]\n",
      " [0.31162791 0.35519481 0.66666667 0.38461538 0.28571429 1.        ]\n",
      " [0.06744186 0.08441558 0.         0.         0.         0.        ]\n",
      " [0.13255814 0.13961039 0.11111111 0.07692308 0.14285714 0.        ]\n",
      " [0.1255814  0.10779221 0.         0.30769231 0.         0.        ]\n",
      " [0.03488372 0.03181818 0.11111111 0.         0.14285714 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because an MLP operates on fixed size inputs, we will use the entire fixed size input for this\n",
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.7771, val_loss = 1.6591\n",
      "Epoch 2\n",
      "train_loss = 1.6317, val_loss = 1.6356\n",
      "Epoch 3\n",
      "train_loss = 1.7473, val_loss = 1.6129\n",
      "Epoch 4\n",
      "train_loss = 1.5172, val_loss = 1.6177\n",
      "Epoch 5\n",
      "train_loss = 1.6969, val_loss = 1.6159\n",
      "Epoch 6\n",
      "train_loss = 1.8144, val_loss = 1.6107\n",
      "Epoch 7\n",
      "train_loss = 1.6213, val_loss = 1.5982\n",
      "Epoch 8\n",
      "train_loss = 1.7224, val_loss = 1.5936\n",
      "Epoch 9\n",
      "train_loss = 1.6084, val_loss = 1.5857\n",
      "Epoch 10\n",
      "train_loss = 1.4453, val_loss = 1.5855\n",
      "Epoch 11\n",
      "train_loss = 1.4773, val_loss = 1.5812\n",
      "Epoch 12\n",
      "train_loss = 1.6663, val_loss = 1.5823\n",
      "Epoch 13\n",
      "train_loss = 1.5502, val_loss = 1.5807\n",
      "Epoch 14\n",
      "train_loss = 1.5330, val_loss = 1.5847\n",
      "Epoch 15\n",
      "train_loss = 1.6405, val_loss = 1.5829\n",
      "Epoch 16\n",
      "train_loss = 1.4082, val_loss = 1.5831\n",
      "Epoch 17\n",
      "train_loss = 1.6473, val_loss = 1.5820\n",
      "Epoch 18\n",
      "train_loss = 1.5996, val_loss = 1.5807\n",
      "Epoch 19\n",
      "train_loss = 1.6273, val_loss = 1.5809\n",
      "Epoch 20\n",
      "train_loss = 1.8354, val_loss = 1.5817\n",
      "Epoch 21\n",
      "train_loss = 1.6578, val_loss = 1.5797\n",
      "Epoch 22\n",
      "train_loss = 1.4926, val_loss = 1.5796\n",
      "Epoch 23\n",
      "train_loss = 1.5391, val_loss = 1.5830\n",
      "Epoch 24\n",
      "train_loss = 1.5061, val_loss = 1.5812\n",
      "Epoch 25\n",
      "train_loss = 1.6384, val_loss = 1.5814\n",
      "Epoch 26\n",
      "train_loss = 1.6114, val_loss = 1.5798\n",
      "Epoch 27\n",
      "train_loss = 1.6473, val_loss = 1.5796\n",
      "Epoch 28\n",
      "train_loss = 1.7043, val_loss = 1.5797\n",
      "Epoch 29\n",
      "train_loss = 1.5017, val_loss = 1.5792\n",
      "Epoch 30\n",
      "train_loss = 1.5853, val_loss = 1.5809\n",
      "Epoch 31\n",
      "train_loss = 1.7743, val_loss = 1.5810\n",
      "Epoch 32\n",
      "train_loss = 1.6940, val_loss = 1.5799\n",
      "Epoch 33\n",
      "train_loss = 1.5962, val_loss = 1.5815\n",
      "Epoch 34\n",
      "train_loss = 1.4598, val_loss = 1.5800\n",
      "Epoch 35\n",
      "train_loss = 1.5833, val_loss = 1.5802\n",
      "Epoch 36\n",
      "train_loss = 1.6352, val_loss = 1.5829\n",
      "Epoch 37\n",
      "train_loss = 1.6292, val_loss = 1.5813\n",
      "Epoch 38\n",
      "train_loss = 1.6014, val_loss = 1.5804\n",
      "Epoch 39\n",
      "train_loss = 1.4930, val_loss = 1.5820\n",
      "Epoch 40\n",
      "train_loss = 1.4782, val_loss = 1.5823\n",
      "Epoch 41\n",
      "train_loss = 1.7585, val_loss = 1.5810\n",
      "Epoch 42\n",
      "train_loss = 1.6580, val_loss = 1.5803\n",
      "Epoch 43\n",
      "train_loss = 1.5544, val_loss = 1.5815\n",
      "Epoch 44\n",
      "train_loss = 1.6004, val_loss = 1.5804\n",
      "Epoch 45\n",
      "train_loss = 1.6286, val_loss = 1.5826\n",
      "Epoch 46\n",
      "train_loss = 1.5710, val_loss = 1.5785\n",
      "Epoch 47\n",
      "train_loss = 1.4145, val_loss = 1.5793\n",
      "Epoch 48\n",
      "train_loss = 1.7138, val_loss = 1.5824\n",
      "Epoch 49\n",
      "train_loss = 1.5820, val_loss = 1.5812\n",
      "Epoch 50\n",
      "train_loss = 1.5647, val_loss = 1.5801\n",
      "Epoch 51\n",
      "train_loss = 1.6992, val_loss = 1.5793\n",
      "Epoch 52\n",
      "train_loss = 1.5950, val_loss = 1.5808\n",
      "Epoch 53\n",
      "train_loss = 1.4528, val_loss = 1.5797\n",
      "Epoch 54\n",
      "train_loss = 1.3336, val_loss = 1.5806\n",
      "Epoch 55\n",
      "train_loss = 1.6458, val_loss = 1.5824\n",
      "Epoch 56\n",
      "train_loss = 1.4795, val_loss = 1.5800\n",
      "Epoch 57\n",
      "train_loss = 1.5099, val_loss = 1.5793\n",
      "Epoch 58\n",
      "train_loss = 1.5925, val_loss = 1.5827\n",
      "Epoch 59\n",
      "train_loss = 1.5454, val_loss = 1.5807\n",
      "Epoch 60\n",
      "train_loss = 1.6837, val_loss = 1.5787\n",
      "Epoch 61\n",
      "train_loss = 1.6136, val_loss = 1.5804\n",
      "Epoch 62\n",
      "train_loss = 1.6888, val_loss = 1.5782\n",
      "Epoch 63\n",
      "train_loss = 1.7401, val_loss = 1.5790\n",
      "Epoch 64\n",
      "train_loss = 1.4828, val_loss = 1.5805\n",
      "Epoch 65\n",
      "train_loss = 1.6555, val_loss = 1.5834\n",
      "Epoch 66\n",
      "train_loss = 1.4459, val_loss = 1.5796\n",
      "Epoch 67\n",
      "train_loss = 1.5749, val_loss = 1.5813\n",
      "Epoch 68\n",
      "train_loss = 1.5597, val_loss = 1.5801\n",
      "Epoch 69\n",
      "train_loss = 1.6221, val_loss = 1.5799\n",
      "Epoch 70\n",
      "train_loss = 1.7423, val_loss = 1.5794\n",
      "Epoch 71\n",
      "train_loss = 1.4053, val_loss = 1.5788\n",
      "Epoch 72\n",
      "train_loss = 1.4858, val_loss = 1.5805\n",
      "Epoch 73\n",
      "train_loss = 1.6927, val_loss = 1.5810\n",
      "Epoch 74\n",
      "train_loss = 1.5508, val_loss = 1.5810\n",
      "Epoch 75\n",
      "train_loss = 1.4821, val_loss = 1.5817\n",
      "Epoch 76\n",
      "train_loss = 1.4129, val_loss = 1.5806\n",
      "Epoch 77\n",
      "train_loss = 1.5524, val_loss = 1.5841\n",
      "Epoch 78\n",
      "train_loss = 1.6025, val_loss = 1.5814\n",
      "Epoch 79\n",
      "train_loss = 1.6241, val_loss = 1.5788\n",
      "Epoch 80\n",
      "train_loss = 1.4311, val_loss = 1.5807\n",
      "Epoch 81\n",
      "train_loss = 1.7000, val_loss = 1.5795\n",
      "Epoch 82\n",
      "train_loss = 1.7623, val_loss = 1.5833\n",
      "Epoch 83\n",
      "train_loss = 1.5965, val_loss = 1.5777\n",
      "Epoch 84\n",
      "train_loss = 1.5850, val_loss = 1.5782\n",
      "Epoch 85\n",
      "train_loss = 1.6302, val_loss = 1.5811\n",
      "Epoch 86\n",
      "train_loss = 1.3657, val_loss = 1.5799\n",
      "Epoch 87\n",
      "train_loss = 1.4792, val_loss = 1.5820\n",
      "Epoch 88\n",
      "train_loss = 1.5329, val_loss = 1.5797\n",
      "Epoch 89\n",
      "train_loss = 1.4679, val_loss = 1.5804\n",
      "Epoch 90\n",
      "train_loss = 1.4958, val_loss = 1.5809\n",
      "Epoch 91\n",
      "train_loss = 1.5719, val_loss = 1.5819\n",
      "Epoch 92\n",
      "train_loss = 1.5152, val_loss = 1.5777\n",
      "Epoch 93\n",
      "train_loss = 1.7578, val_loss = 1.5787\n",
      "Epoch 94\n",
      "train_loss = 1.5205, val_loss = 1.5813\n",
      "Epoch 95\n",
      "train_loss = 1.5871, val_loss = 1.5803\n",
      "Epoch 96\n",
      "train_loss = 1.7054, val_loss = 1.5797\n",
      "Epoch 97\n",
      "train_loss = 1.6011, val_loss = 1.5806\n",
      "Epoch 98\n",
      "train_loss = 1.6977, val_loss = 1.5813\n",
      "Epoch 99\n",
      "train_loss = 1.5185, val_loss = 1.5798\n",
      "Epoch 100\n",
      "train_loss = 1.4356, val_loss = 1.5835\n",
      "Epoch 101\n",
      "train_loss = 1.5064, val_loss = 1.5790\n",
      "Epoch 102\n",
      "train_loss = 1.6789, val_loss = 1.5808\n",
      "Epoch 103\n",
      "train_loss = 1.4798, val_loss = 1.5797\n",
      "Epoch 104\n",
      "train_loss = 1.6142, val_loss = 1.5790\n",
      "Epoch 105\n",
      "train_loss = 1.5928, val_loss = 1.5826\n",
      "Epoch 106\n",
      "train_loss = 1.5056, val_loss = 1.5815\n",
      "Epoch 107\n",
      "train_loss = 1.3801, val_loss = 1.5791\n",
      "Epoch 108\n",
      "train_loss = 1.6443, val_loss = 1.5819\n",
      "Epoch 109\n",
      "train_loss = 1.4442, val_loss = 1.5828\n",
      "Epoch 110\n",
      "train_loss = 1.4687, val_loss = 1.5792\n",
      "Epoch 111\n",
      "train_loss = 1.7605, val_loss = 1.5775\n",
      "Epoch 112\n",
      "train_loss = 1.7588, val_loss = 1.5832\n",
      "Epoch 113\n",
      "train_loss = 1.5392, val_loss = 1.5817\n",
      "Epoch 114\n",
      "train_loss = 1.5406, val_loss = 1.5817\n",
      "Epoch 115\n",
      "train_loss = 1.5334, val_loss = 1.5819\n",
      "Epoch 116\n",
      "train_loss = 1.7382, val_loss = 1.5829\n",
      "Epoch 117\n",
      "train_loss = 1.5775, val_loss = 1.5822\n",
      "Epoch 118\n",
      "train_loss = 1.4638, val_loss = 1.5800\n",
      "Epoch 119\n",
      "train_loss = 1.6202, val_loss = 1.5816\n",
      "Epoch 120\n",
      "train_loss = 1.6064, val_loss = 1.5827\n",
      "Epoch 121\n",
      "train_loss = 1.6648, val_loss = 1.5781\n",
      "Epoch 122\n",
      "train_loss = 1.5476, val_loss = 1.5846\n",
      "Epoch 123\n",
      "train_loss = 1.5573, val_loss = 1.5866\n",
      "Epoch 124\n",
      "train_loss = 1.6703, val_loss = 1.5860\n",
      "Epoch 125\n",
      "train_loss = 1.4551, val_loss = 1.5838\n",
      "Epoch 126\n",
      "train_loss = 1.5478, val_loss = 1.5827\n",
      "Epoch 127\n",
      "train_loss = 1.7235, val_loss = 1.5815\n",
      "Epoch 128\n",
      "train_loss = 1.4817, val_loss = 1.5818\n",
      "Epoch 129\n",
      "train_loss = 1.4782, val_loss = 1.5798\n",
      "Epoch 130\n",
      "train_loss = 1.5775, val_loss = 1.5810\n",
      "Epoch 131\n",
      "train_loss = 1.4650, val_loss = 1.5819\n",
      "Epoch 132\n",
      "train_loss = 1.5585, val_loss = 1.5783\n",
      "Epoch 133\n",
      "train_loss = 1.5647, val_loss = 1.5793\n",
      "Epoch 134\n",
      "train_loss = 1.5254, val_loss = 1.5851\n",
      "Epoch 135\n",
      "train_loss = 1.6489, val_loss = 1.5836\n",
      "Epoch 136\n",
      "train_loss = 1.4981, val_loss = 1.5852\n",
      "Epoch 137\n",
      "train_loss = 1.5047, val_loss = 1.5798\n",
      "Epoch 138\n",
      "train_loss = 1.5055, val_loss = 1.5827\n",
      "Epoch 139\n",
      "train_loss = 1.7710, val_loss = 1.5839\n",
      "Epoch 140\n",
      "train_loss = 1.5417, val_loss = 1.5848\n",
      "Epoch 141\n",
      "train_loss = 1.7174, val_loss = 1.5819\n",
      "Epoch 142\n",
      "train_loss = 1.5207, val_loss = 1.5792\n",
      "Epoch 143\n",
      "train_loss = 1.4186, val_loss = 1.5801\n",
      "Epoch 144\n",
      "train_loss = 1.4957, val_loss = 1.5791\n",
      "Epoch 145\n",
      "train_loss = 1.8050, val_loss = 1.5825\n",
      "Epoch 146\n",
      "train_loss = 1.4090, val_loss = 1.5837\n",
      "Epoch 147\n",
      "train_loss = 1.5483, val_loss = 1.5853\n",
      "Epoch 148\n",
      "train_loss = 1.6571, val_loss = 1.5843\n",
      "Epoch 149\n",
      "train_loss = 1.5195, val_loss = 1.5842\n",
      "Epoch 150\n",
      "train_loss = 1.7193, val_loss = 1.5847\n",
      "Epoch 151\n",
      "train_loss = 1.4928, val_loss = 1.5848\n",
      "Epoch 152\n",
      "train_loss = 1.6117, val_loss = 1.5784\n",
      "Epoch 153\n",
      "train_loss = 1.5432, val_loss = 1.5842\n",
      "Epoch 154\n",
      "train_loss = 1.4947, val_loss = 1.5832\n",
      "Epoch 155\n",
      "train_loss = 1.4587, val_loss = 1.5893\n",
      "Epoch 156\n",
      "train_loss = 1.4852, val_loss = 1.5840\n",
      "Epoch 157\n",
      "train_loss = 1.5266, val_loss = 1.5856\n",
      "Epoch 158\n",
      "train_loss = 1.5955, val_loss = 1.5851\n",
      "Epoch 159\n",
      "train_loss = 1.6292, val_loss = 1.5807\n",
      "Epoch 160\n",
      "train_loss = 1.6392, val_loss = 1.5818\n",
      "Epoch 161\n",
      "train_loss = 1.3960, val_loss = 1.5881\n",
      "Epoch 162\n",
      "train_loss = 1.4568, val_loss = 1.5897\n",
      "Epoch 163\n",
      "train_loss = 1.5496, val_loss = 1.5847\n",
      "Epoch 164\n",
      "train_loss = 1.5721, val_loss = 1.5789\n",
      "Epoch 165\n",
      "train_loss = 1.6089, val_loss = 1.5827\n",
      "Epoch 166\n",
      "train_loss = 1.5376, val_loss = 1.5825\n",
      "Epoch 167\n",
      "train_loss = 1.7186, val_loss = 1.5881\n",
      "Epoch 168\n",
      "train_loss = 1.4815, val_loss = 1.5860\n",
      "Epoch 169\n",
      "train_loss = 1.6615, val_loss = 1.5854\n",
      "Epoch 170\n",
      "train_loss = 1.5599, val_loss = 1.5852\n",
      "Epoch 171\n",
      "train_loss = 1.6191, val_loss = 1.5853\n",
      "Epoch 172\n",
      "train_loss = 1.4232, val_loss = 1.5868\n",
      "Epoch 173\n",
      "train_loss = 1.6664, val_loss = 1.5845\n",
      "Epoch 174\n",
      "train_loss = 1.4999, val_loss = 1.5877\n",
      "Epoch 175\n",
      "train_loss = 1.5175, val_loss = 1.5907\n",
      "Epoch 176\n",
      "train_loss = 1.6044, val_loss = 1.5853\n",
      "Epoch 177\n",
      "train_loss = 1.4624, val_loss = 1.5844\n",
      "Epoch 178\n",
      "train_loss = 1.5223, val_loss = 1.5863\n",
      "Epoch 179\n",
      "train_loss = 1.6669, val_loss = 1.5907\n",
      "Epoch 180\n",
      "train_loss = 1.5265, val_loss = 1.5882\n",
      "Epoch 181\n",
      "train_loss = 1.6982, val_loss = 1.5850\n",
      "Epoch 182\n",
      "train_loss = 1.5344, val_loss = 1.5878\n",
      "Epoch 183\n",
      "train_loss = 1.5964, val_loss = 1.5895\n",
      "Epoch 184\n",
      "train_loss = 1.6854, val_loss = 1.5866\n",
      "Epoch 185\n",
      "train_loss = 1.4908, val_loss = 1.5947\n",
      "Epoch 186\n",
      "train_loss = 1.7217, val_loss = 1.5855\n",
      "Epoch 187\n",
      "train_loss = 1.5094, val_loss = 1.5839\n",
      "Epoch 188\n",
      "train_loss = 1.4540, val_loss = 1.5867\n",
      "Epoch 189\n",
      "train_loss = 1.3813, val_loss = 1.5881\n",
      "Epoch 190\n",
      "train_loss = 1.6206, val_loss = 1.5901\n",
      "Epoch 191\n",
      "train_loss = 1.6822, val_loss = 1.5873\n",
      "Epoch 192\n",
      "train_loss = 1.5175, val_loss = 1.5850\n",
      "Epoch 193\n",
      "train_loss = 1.6253, val_loss = 1.5858\n",
      "Epoch 194\n",
      "train_loss = 1.6752, val_loss = 1.5901\n",
      "Epoch 195\n",
      "train_loss = 1.6101, val_loss = 1.5855\n",
      "Epoch 196\n",
      "train_loss = 1.3145, val_loss = 1.5866\n",
      "Epoch 197\n",
      "train_loss = 1.3644, val_loss = 1.5860\n",
      "Epoch 198\n",
      "train_loss = 1.8137, val_loss = 1.5891\n",
      "Epoch 199\n",
      "train_loss = 1.4755, val_loss = 1.5866\n",
      "Epoch 200\n",
      "train_loss = 1.6712, val_loss = 1.5884\n",
      "Epoch 201\n",
      "train_loss = 1.4398, val_loss = 1.5926\n"
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [100, 100, 100], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE, path=\"models/mlpseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.5655\n",
      "accuracy = 0.3370\n",
      "f1 = 0.2498\n",
      "[[0.29693487 0.28834356 0.         0.33333333 0.2        0.        ]\n",
      " [0.33333333 0.3524199  0.         0.16666667 0.6        0.        ]\n",
      " [0.07279693 0.08248125 0.         0.         0.         0.        ]\n",
      " [0.13601533 0.13769598 0.         0.33333333 0.         0.        ]\n",
      " [0.13409962 0.10497614 0.         0.         0.         0.        ]\n",
      " [0.02681992 0.03408316 0.         0.16666667 0.2        0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.8983, val_loss = 1.7939\n",
      "Epoch 2\n",
      "train_loss = 1.8004, val_loss = 1.7927\n",
      "Epoch 3\n",
      "train_loss = 1.8076, val_loss = 1.7933\n",
      "Epoch 4\n",
      "train_loss = 1.8109, val_loss = 1.7920\n",
      "Epoch 5\n",
      "train_loss = 1.7929, val_loss = 1.7919\n",
      "Epoch 6\n",
      "train_loss = 1.8069, val_loss = 1.7935\n",
      "Epoch 7\n",
      "train_loss = 1.8155, val_loss = 1.7924\n",
      "Epoch 8\n",
      "train_loss = 1.7893, val_loss = 1.7927\n",
      "Epoch 9\n",
      "train_loss = 1.7808, val_loss = 1.7925\n",
      "Epoch 10\n",
      "train_loss = 1.7802, val_loss = 1.7931\n",
      "Epoch 11\n",
      "train_loss = 1.7819, val_loss = 1.7930\n",
      "Epoch 12\n",
      "train_loss = 1.7850, val_loss = 1.7935\n",
      "Epoch 13\n",
      "train_loss = 1.7805, val_loss = 1.7936\n",
      "Epoch 14\n",
      "train_loss = 1.7712, val_loss = 1.7931\n",
      "Epoch 15\n",
      "train_loss = 1.7852, val_loss = 1.7949\n",
      "Epoch 16\n",
      "train_loss = 1.7995, val_loss = 1.7924\n",
      "Epoch 17\n",
      "train_loss = 1.7999, val_loss = 1.7932\n",
      "Epoch 18\n",
      "train_loss = 1.8206, val_loss = 1.7924\n",
      "Epoch 19\n",
      "train_loss = 1.8954, val_loss = 1.7920\n",
      "Epoch 20\n",
      "train_loss = 1.8096, val_loss = 1.7940\n",
      "Epoch 21\n",
      "train_loss = 1.7956, val_loss = 1.7925\n",
      "Epoch 22\n",
      "train_loss = 1.7715, val_loss = 1.7939\n",
      "Epoch 23\n",
      "train_loss = 1.7892, val_loss = 1.7933\n",
      "Epoch 24\n",
      "train_loss = 1.7834, val_loss = 1.7938\n",
      "Epoch 25\n",
      "train_loss = 1.7675, val_loss = 1.7931\n",
      "Epoch 26\n",
      "train_loss = 1.7808, val_loss = 1.7926\n",
      "Epoch 27\n",
      "train_loss = 1.8059, val_loss = 1.7976\n",
      "Epoch 28\n",
      "train_loss = 1.7951, val_loss = 1.7932\n",
      "Epoch 29\n",
      "train_loss = 1.8074, val_loss = 1.7939\n",
      "Epoch 30\n",
      "train_loss = 1.7840, val_loss = 1.7920\n",
      "Epoch 31\n",
      "train_loss = 1.7775, val_loss = 1.7930\n",
      "Epoch 32\n",
      "train_loss = 1.7402, val_loss = 1.7948\n",
      "Epoch 33\n",
      "train_loss = 1.7567, val_loss = 1.7926\n",
      "Epoch 34\n",
      "train_loss = 1.7352, val_loss = 1.7928\n",
      "Epoch 35\n",
      "train_loss = 1.7635, val_loss = 1.7939\n",
      "Epoch 36\n",
      "train_loss = 1.8022, val_loss = 1.7913\n",
      "Epoch 37\n",
      "train_loss = 1.7623, val_loss = 1.7926\n",
      "Epoch 38\n",
      "train_loss = 1.7845, val_loss = 1.7927\n",
      "Epoch 39\n",
      "train_loss = 1.7692, val_loss = 1.7928\n",
      "Epoch 40\n",
      "train_loss = 1.7940, val_loss = 1.7917\n",
      "Epoch 41\n",
      "train_loss = 1.8060, val_loss = 1.7932\n",
      "Epoch 42\n",
      "train_loss = 1.7830, val_loss = 1.7934\n",
      "Epoch 43\n",
      "train_loss = 1.7737, val_loss = 1.7928\n",
      "Epoch 44\n",
      "train_loss = 1.7755, val_loss = 1.7961\n",
      "Epoch 45\n",
      "train_loss = 1.7911, val_loss = 1.7941\n",
      "Epoch 46\n",
      "train_loss = 1.7773, val_loss = 1.7946\n",
      "Epoch 47\n",
      "train_loss = 1.7838, val_loss = 1.7928\n",
      "Epoch 48\n",
      "train_loss = 1.7712, val_loss = 1.7930\n",
      "Epoch 49\n",
      "train_loss = 1.7709, val_loss = 1.7964\n",
      "Epoch 50\n",
      "train_loss = 1.7885, val_loss = 1.7926\n",
      "Epoch 51\n",
      "train_loss = 1.7751, val_loss = 1.7923\n",
      "Epoch 52\n",
      "train_loss = 1.7508, val_loss = 1.7951\n",
      "Epoch 53\n",
      "train_loss = 1.7777, val_loss = 1.7924\n",
      "Epoch 54\n",
      "train_loss = 1.7904, val_loss = 1.7921\n",
      "Epoch 55\n",
      "train_loss = 1.7707, val_loss = 1.7930\n",
      "Epoch 56\n",
      "train_loss = 1.7843, val_loss = 1.7912\n",
      "Epoch 57\n",
      "train_loss = 1.7689, val_loss = 1.7935\n",
      "Epoch 58\n",
      "train_loss = 1.7775, val_loss = 1.7987\n",
      "Epoch 59\n",
      "train_loss = 1.7821, val_loss = 1.7918\n",
      "Epoch 60\n",
      "train_loss = 1.8286, val_loss = 1.7917\n",
      "Epoch 61\n",
      "train_loss = 1.7554, val_loss = 1.7980\n",
      "Epoch 62\n",
      "train_loss = 1.7897, val_loss = 1.7929\n",
      "Epoch 63\n",
      "train_loss = 1.8584, val_loss = 1.7997\n",
      "Epoch 64\n",
      "train_loss = 1.7405, val_loss = 1.7951\n",
      "Epoch 65\n",
      "train_loss = 1.7745, val_loss = 1.7941\n",
      "Epoch 66\n",
      "train_loss = 1.7798, val_loss = 1.7955\n",
      "Epoch 67\n",
      "train_loss = 1.8697, val_loss = 1.7915\n",
      "Epoch 68\n",
      "train_loss = 1.7966, val_loss = 1.7939\n",
      "Epoch 69\n",
      "train_loss = 1.7802, val_loss = 1.7921\n",
      "Epoch 70\n",
      "train_loss = 1.7799, val_loss = 1.7967\n",
      "Epoch 71\n",
      "train_loss = 1.7784, val_loss = 1.7945\n",
      "Epoch 72\n",
      "train_loss = 1.7969, val_loss = 1.7983\n",
      "Epoch 73\n",
      "train_loss = 1.7825, val_loss = 1.7988\n",
      "Epoch 74\n",
      "train_loss = 1.7713, val_loss = 1.7978\n",
      "Epoch 75\n",
      "train_loss = 1.7857, val_loss = 1.7950\n",
      "Epoch 76\n",
      "train_loss = 1.7900, val_loss = 1.7981\n",
      "Epoch 77\n",
      "train_loss = 1.7616, val_loss = 1.7991\n",
      "Epoch 78\n",
      "train_loss = 1.7761, val_loss = 1.7973\n",
      "Epoch 79\n",
      "train_loss = 1.7677, val_loss = 1.7996\n",
      "Epoch 80\n",
      "train_loss = 1.7581, val_loss = 1.8098\n",
      "Epoch 81\n",
      "train_loss = 1.7749, val_loss = 1.8009\n",
      "Epoch 82\n",
      "train_loss = 1.7908, val_loss = 1.7994\n",
      "Epoch 83\n",
      "train_loss = 1.7803, val_loss = 1.8013\n",
      "Epoch 84\n",
      "train_loss = 1.7702, val_loss = 1.8068\n",
      "Epoch 85\n",
      "train_loss = 1.7714, val_loss = 1.7999\n",
      "Epoch 86\n",
      "train_loss = 1.7975, val_loss = 1.8052\n",
      "Epoch 87\n",
      "train_loss = 1.7729, val_loss = 1.7982\n",
      "Epoch 88\n",
      "train_loss = 1.7692, val_loss = 1.8025\n",
      "Epoch 89\n",
      "train_loss = 1.8112, val_loss = 1.7973\n",
      "Epoch 90\n",
      "train_loss = 1.8024, val_loss = 1.8094\n",
      "Epoch 91\n",
      "train_loss = 1.7678, val_loss = 1.8013\n",
      "Epoch 92\n",
      "train_loss = 1.7855, val_loss = 1.8013\n",
      "Epoch 93\n",
      "train_loss = 1.8088, val_loss = 1.7959\n",
      "Epoch 94\n",
      "train_loss = 1.8125, val_loss = 1.8070\n",
      "Epoch 95\n",
      "train_loss = 1.7666, val_loss = 1.8014\n",
      "Epoch 96\n",
      "train_loss = 1.8057, val_loss = 1.8025\n",
      "Epoch 97\n",
      "train_loss = 1.7747, val_loss = 1.7983\n",
      "Epoch 98\n",
      "train_loss = 1.7818, val_loss = 1.8010\n",
      "Epoch 99\n",
      "train_loss = 1.8019, val_loss = 1.8033\n",
      "Epoch 100\n",
      "train_loss = 1.8142, val_loss = 1.8122\n"
     ]
    }
   ],
   "source": [
    "mlp = NeuralNetwork(max_toks, [100, 100, 100], NUM_CLASSES, device=\"cuda\")\n",
    "training_loop(mlp, train_loader, val_loader, epochs=100, learning_rate=LEARNING_RATE, path=\"models/mlpseqwt\", weights=WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.7646\n",
      "accuracy = 0.2470\n",
      "f1 = 0.2438\n",
      "[[0.29005059 0.28236915 0.30215827 0.27906977 0.33469388 0.20512821]\n",
      " [0.35244519 0.35261708 0.30935252 0.37209302 0.32653061 0.28205128]\n",
      " [0.08937605 0.06473829 0.09352518 0.08914729 0.06938776 0.15384615]\n",
      " [0.13827993 0.13085399 0.15827338 0.12403101 0.14693878 0.20512821]\n",
      " [0.09612142 0.12809917 0.12230216 0.11627907 0.08571429 0.15384615]\n",
      " [0.03372681 0.04132231 0.01438849 0.01937984 0.03673469 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=mlp, val_dl=test_loader)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks, dtype = torch.int32)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss = 1.7882, val_loss = 1.7931\n",
      "Epoch 2\n",
      "train_loss = 1.8260, val_loss = 1.7939\n",
      "Epoch 3\n",
      "train_loss = 1.7908, val_loss = 1.7924\n",
      "Epoch 4\n",
      "train_loss = 1.7708, val_loss = 1.7925\n",
      "Epoch 5\n",
      "train_loss = 1.7943, val_loss = 1.7918\n",
      "Epoch 6\n",
      "train_loss = 1.7822, val_loss = 1.7915\n",
      "Epoch 7\n",
      "train_loss = 1.8270, val_loss = 1.7942\n",
      "Epoch 8\n",
      "train_loss = 1.8130, val_loss = 1.7926\n",
      "Epoch 9\n",
      "train_loss = 1.7885, val_loss = 1.7944\n",
      "Epoch 10\n",
      "train_loss = 1.7661, val_loss = 1.7928\n",
      "Epoch 11\n",
      "train_loss = 1.7836, val_loss = 1.7929\n",
      "Epoch 12\n",
      "train_loss = 1.8205, val_loss = 1.7944\n",
      "Epoch 13\n",
      "train_loss = 1.8072, val_loss = 1.7950\n",
      "Epoch 14\n",
      "train_loss = 1.7822, val_loss = 1.7927\n",
      "Epoch 15\n",
      "train_loss = 1.8481, val_loss = 1.7922\n",
      "Epoch 16\n",
      "train_loss = 1.7848, val_loss = 1.7923\n",
      "Epoch 17\n",
      "train_loss = 1.7909, val_loss = 1.7921\n",
      "Epoch 18\n",
      "train_loss = 1.7669, val_loss = 1.7921\n",
      "Epoch 19\n",
      "train_loss = 1.8121, val_loss = 1.7944\n",
      "Epoch 20\n",
      "train_loss = 1.8022, val_loss = 1.7946\n",
      "Epoch 21\n",
      "train_loss = 1.7814, val_loss = 1.7928\n",
      "Epoch 22\n",
      "train_loss = 1.8101, val_loss = 1.7932\n",
      "Epoch 23\n",
      "train_loss = 1.7955, val_loss = 1.7938\n",
      "Epoch 24\n",
      "train_loss = 1.7893, val_loss = 1.7929\n",
      "Epoch 25\n",
      "train_loss = 1.7703, val_loss = 1.7935\n",
      "Epoch 26\n",
      "train_loss = 1.7854, val_loss = 1.7949\n",
      "Epoch 27\n",
      "train_loss = 1.7941, val_loss = 1.7937\n",
      "Epoch 28\n",
      "train_loss = 1.7610, val_loss = 1.7926\n",
      "Epoch 29\n",
      "train_loss = 1.7768, val_loss = 1.7938\n",
      "Epoch 30\n",
      "train_loss = 1.7967, val_loss = 1.7936\n",
      "Epoch 31\n",
      "train_loss = 1.7769, val_loss = 1.7949\n",
      "Epoch 32\n",
      "train_loss = 1.7818, val_loss = 1.7942\n",
      "Epoch 33\n",
      "train_loss = 1.7676, val_loss = 1.7932\n",
      "Epoch 34\n",
      "train_loss = 1.7922, val_loss = 1.7924\n",
      "Epoch 35\n",
      "train_loss = 1.7800, val_loss = 1.7919\n",
      "Epoch 36\n",
      "train_loss = 1.7930, val_loss = 1.7939\n",
      "Epoch 37\n",
      "train_loss = 1.7858, val_loss = 1.7926\n",
      "Epoch 38\n",
      "train_loss = 1.7957, val_loss = 1.7931\n",
      "Epoch 39\n",
      "train_loss = 1.7775, val_loss = 1.7917\n",
      "Epoch 40\n",
      "train_loss = 1.8126, val_loss = 1.7934\n",
      "Epoch 41\n",
      "train_loss = 1.8071, val_loss = 1.7919\n",
      "Epoch 42\n",
      "train_loss = 1.7778, val_loss = 1.7924\n",
      "Epoch 43\n",
      "train_loss = 1.7931, val_loss = 1.7915\n",
      "Epoch 44\n",
      "train_loss = 1.7919, val_loss = 1.7938\n",
      "Epoch 45\n",
      "train_loss = 1.7870, val_loss = 1.7934\n",
      "Epoch 46\n",
      "train_loss = 1.7648, val_loss = 1.7931\n",
      "Epoch 47\n",
      "train_loss = 1.7905, val_loss = 1.7940\n",
      "Epoch 48\n",
      "train_loss = 1.8029, val_loss = 1.7933\n",
      "Epoch 49\n",
      "train_loss = 1.7773, val_loss = 1.7930\n",
      "Epoch 50\n",
      "train_loss = 1.8369, val_loss = 1.7921\n",
      "Epoch 51\n",
      "train_loss = 1.7728, val_loss = 1.7931\n",
      "Epoch 52\n",
      "train_loss = 1.7935, val_loss = 1.7925\n",
      "Epoch 53\n",
      "train_loss = 1.7801, val_loss = 1.7912\n",
      "Epoch 54\n",
      "train_loss = 1.7860, val_loss = 1.7934\n",
      "Epoch 55\n",
      "train_loss = 1.8059, val_loss = 1.7926\n",
      "Epoch 56\n",
      "train_loss = 1.7772, val_loss = 1.7966\n",
      "Epoch 57\n",
      "train_loss = 1.8013, val_loss = 1.7939\n",
      "Epoch 58\n",
      "train_loss = 1.7798, val_loss = 1.7923\n",
      "Epoch 59\n",
      "train_loss = 1.7894, val_loss = 1.7928\n",
      "Epoch 60\n",
      "train_loss = 1.8154, val_loss = 1.7920\n",
      "Epoch 61\n",
      "train_loss = 1.7791, val_loss = 1.7922\n",
      "Epoch 62\n",
      "train_loss = 1.7827, val_loss = 1.7943\n",
      "Epoch 63\n",
      "train_loss = 1.7615, val_loss = 1.7931\n",
      "Epoch 64\n",
      "train_loss = 1.8020, val_loss = 1.7930\n",
      "Epoch 65\n",
      "train_loss = 1.7765, val_loss = 1.7938\n",
      "Epoch 66\n",
      "train_loss = 1.7891, val_loss = 1.7922\n",
      "Epoch 67\n",
      "train_loss = 1.8146, val_loss = 1.7938\n",
      "Epoch 68\n",
      "train_loss = 1.7884, val_loss = 1.7924\n",
      "Epoch 69\n",
      "train_loss = 1.8076, val_loss = 1.7925\n",
      "Epoch 70\n",
      "train_loss = 1.7894, val_loss = 1.7934\n",
      "Epoch 71\n",
      "train_loss = 1.7505, val_loss = 1.7937\n",
      "Epoch 72\n",
      "train_loss = 1.7834, val_loss = 1.7914\n",
      "Epoch 73\n",
      "train_loss = 1.7844, val_loss = 1.7901\n",
      "Epoch 74\n",
      "train_loss = 1.7817, val_loss = 1.7943\n",
      "Epoch 75\n",
      "train_loss = 1.7681, val_loss = 1.7941\n",
      "Epoch 76\n",
      "train_loss = 1.8093, val_loss = 1.7913\n",
      "Epoch 77\n",
      "train_loss = 1.7879, val_loss = 1.7943\n",
      "Epoch 78\n",
      "train_loss = 1.8003, val_loss = 1.7951\n",
      "Epoch 79\n",
      "train_loss = 1.8109, val_loss = 1.7933\n",
      "Epoch 80\n",
      "train_loss = 1.7960, val_loss = 1.7934\n",
      "Epoch 81\n",
      "train_loss = 1.8135, val_loss = 1.7943\n",
      "Epoch 82\n",
      "train_loss = 1.7778, val_loss = 1.7935\n",
      "Epoch 83\n",
      "train_loss = 1.7640, val_loss = 1.7923\n",
      "Epoch 84\n",
      "train_loss = 1.7934, val_loss = 1.7936\n",
      "Epoch 85\n",
      "train_loss = 1.7820, val_loss = 1.7910\n",
      "Epoch 86\n",
      "train_loss = 1.7904, val_loss = 1.7939\n",
      "Epoch 87\n",
      "train_loss = 1.8276, val_loss = 1.7926\n",
      "Epoch 88\n",
      "train_loss = 1.7819, val_loss = 1.7917\n",
      "Epoch 89\n",
      "train_loss = 1.7824, val_loss = 1.7921\n",
      "Epoch 90\n",
      "train_loss = 1.8103, val_loss = 1.7944\n",
      "Epoch 91\n",
      "train_loss = 1.7702, val_loss = 1.7912\n",
      "Epoch 92\n",
      "train_loss = 1.7634, val_loss = 1.7924\n",
      "Epoch 93\n",
      "train_loss = 1.7554, val_loss = 1.7930\n",
      "Epoch 94\n",
      "train_loss = 1.7951, val_loss = 1.7939\n",
      "Epoch 95\n",
      "train_loss = 1.7897, val_loss = 1.7931\n",
      "Epoch 96\n",
      "train_loss = 1.8017, val_loss = 1.7932\n",
      "Epoch 97\n",
      "train_loss = 1.7797, val_loss = 1.7916\n",
      "Epoch 98\n",
      "train_loss = 1.7759, val_loss = 1.7922\n",
      "Epoch 99\n",
      "train_loss = 1.7628, val_loss = 1.7924\n",
      "Epoch 100\n",
      "train_loss = 1.7546, val_loss = 1.7943\n",
      "Epoch 101\n",
      "train_loss = 1.7929, val_loss = 1.7918\n",
      "Epoch 102\n",
      "train_loss = 1.7991, val_loss = 1.7930\n",
      "Epoch 103\n",
      "train_loss = 1.7952, val_loss = 1.7939\n",
      "Epoch 104\n",
      "train_loss = 1.7881, val_loss = 1.7927\n",
      "Epoch 105\n",
      "train_loss = 1.8091, val_loss = 1.7923\n",
      "Epoch 106\n",
      "train_loss = 1.7964, val_loss = 1.7915\n",
      "Epoch 107\n",
      "train_loss = 1.7890, val_loss = 1.7934\n",
      "Epoch 108\n",
      "train_loss = 1.8025, val_loss = 1.7929\n",
      "Epoch 109\n",
      "train_loss = 1.8042, val_loss = 1.7941\n",
      "Epoch 110\n",
      "train_loss = 1.7770, val_loss = 1.7942\n",
      "Epoch 111\n",
      "train_loss = 1.7992, val_loss = 1.7928\n",
      "Epoch 112\n",
      "train_loss = 1.7876, val_loss = 1.7933\n",
      "Epoch 113\n",
      "train_loss = 1.8079, val_loss = 1.7924\n",
      "Epoch 114\n",
      "train_loss = 1.7750, val_loss = 1.7918\n",
      "Epoch 115\n",
      "train_loss = 1.7893, val_loss = 1.7955\n",
      "Epoch 116\n",
      "train_loss = 1.7877, val_loss = 1.7928\n",
      "Epoch 117\n",
      "train_loss = 1.7913, val_loss = 1.7945\n",
      "Epoch 118\n",
      "train_loss = 1.7950, val_loss = 1.7939\n",
      "Epoch 119\n",
      "train_loss = 1.7678, val_loss = 1.7925\n",
      "Epoch 120\n",
      "train_loss = 1.7920, val_loss = 1.7941\n",
      "Epoch 121\n",
      "train_loss = 1.7821, val_loss = 1.7918\n",
      "Epoch 122\n",
      "train_loss = 1.8031, val_loss = 1.7929\n",
      "Epoch 123\n",
      "train_loss = 1.7800, val_loss = 1.7931\n",
      "Epoch 124\n",
      "train_loss = 1.7880, val_loss = 1.7925\n",
      "Epoch 125\n",
      "train_loss = 1.8166, val_loss = 1.7956\n",
      "Epoch 126\n",
      "train_loss = 1.7574, val_loss = 1.7915\n",
      "Epoch 127\n",
      "train_loss = 1.8466, val_loss = 1.7948\n",
      "Epoch 128\n",
      "train_loss = 1.7685, val_loss = 1.7915\n",
      "Epoch 129\n",
      "train_loss = 1.8103, val_loss = 1.7922\n",
      "Epoch 130\n",
      "train_loss = 1.7665, val_loss = 1.7929\n",
      "Epoch 131\n",
      "train_loss = 1.7813, val_loss = 1.7918\n",
      "Epoch 132\n",
      "train_loss = 1.7692, val_loss = 1.7935\n",
      "Epoch 133\n",
      "train_loss = 1.7899, val_loss = 1.7949\n",
      "Epoch 134\n",
      "train_loss = 1.7802, val_loss = 1.7932\n",
      "Epoch 135\n",
      "train_loss = 1.7516, val_loss = 1.7921\n",
      "Epoch 136\n",
      "train_loss = 1.8051, val_loss = 1.7930\n",
      "Epoch 137\n",
      "train_loss = 1.7811, val_loss = 1.7942\n",
      "Epoch 138\n",
      "train_loss = 1.7888, val_loss = 1.7949\n",
      "Epoch 139\n",
      "train_loss = 1.7888, val_loss = 1.7945\n",
      "Epoch 140\n",
      "train_loss = 1.7555, val_loss = 1.7912\n",
      "Epoch 141\n",
      "train_loss = 1.7975, val_loss = 1.7949\n",
      "Epoch 142\n",
      "train_loss = 1.7703, val_loss = 1.7937\n",
      "Epoch 143\n",
      "train_loss = 1.7791, val_loss = 1.7930\n",
      "Epoch 144\n",
      "train_loss = 1.7737, val_loss = 1.7943\n",
      "Epoch 145\n",
      "train_loss = 1.7961, val_loss = 1.7935\n",
      "Epoch 146\n",
      "train_loss = 1.7828, val_loss = 1.7919\n",
      "Epoch 147\n",
      "train_loss = 1.7754, val_loss = 1.7941\n",
      "Epoch 148\n",
      "train_loss = 1.8056, val_loss = 1.7917\n",
      "Epoch 149\n",
      "train_loss = 1.7838, val_loss = 1.7926\n",
      "Epoch 150\n",
      "train_loss = 1.7604, val_loss = 1.7932\n",
      "Epoch 151\n",
      "train_loss = 1.7771, val_loss = 1.7935\n",
      "Epoch 152\n",
      "train_loss = 1.8009, val_loss = 1.7924\n",
      "Epoch 153\n",
      "train_loss = 1.7883, val_loss = 1.7932\n",
      "Epoch 154\n",
      "train_loss = 1.7863, val_loss = 1.7953\n",
      "Epoch 155\n",
      "train_loss = 1.7765, val_loss = 1.7924\n",
      "Epoch 156\n",
      "train_loss = 1.7774, val_loss = 1.7952\n",
      "Epoch 157\n",
      "train_loss = 1.7944, val_loss = 1.7960\n",
      "Epoch 158\n",
      "train_loss = 1.7825, val_loss = 1.7917\n",
      "Epoch 159\n",
      "train_loss = 1.7911, val_loss = 1.7942\n",
      "Epoch 160\n",
      "train_loss = 1.7590, val_loss = 1.7902\n",
      "Epoch 161\n",
      "train_loss = 1.8046, val_loss = 1.7954\n",
      "Epoch 162\n",
      "train_loss = 1.7696, val_loss = 1.7934\n",
      "Epoch 163\n",
      "train_loss = 1.7985, val_loss = 1.7940\n",
      "Epoch 164\n",
      "train_loss = 1.8071, val_loss = 1.7923\n",
      "Epoch 165\n",
      "train_loss = 1.7666, val_loss = 1.7938\n",
      "Epoch 166\n",
      "train_loss = 1.8173, val_loss = 1.7943\n",
      "Epoch 167\n",
      "train_loss = 1.8103, val_loss = 1.7927\n",
      "Epoch 168\n",
      "train_loss = 1.7763, val_loss = 1.7925\n",
      "Epoch 169\n",
      "train_loss = 1.7802, val_loss = 1.7927\n",
      "Epoch 170\n",
      "train_loss = 1.7863, val_loss = 1.7936\n",
      "Epoch 171\n",
      "train_loss = 1.7848, val_loss = 1.7946\n",
      "Epoch 172\n",
      "train_loss = 1.7727, val_loss = 1.7919\n",
      "Epoch 173\n",
      "train_loss = 1.8083, val_loss = 1.7950\n",
      "Epoch 174\n",
      "train_loss = 1.7774, val_loss = 1.7922\n",
      "Epoch 175\n",
      "train_loss = 1.7714, val_loss = 1.7940\n",
      "Epoch 176\n",
      "train_loss = 1.8155, val_loss = 1.7944\n",
      "Epoch 177\n",
      "train_loss = 1.7723, val_loss = 1.7913\n",
      "Epoch 178\n",
      "train_loss = 1.8021, val_loss = 1.7931\n",
      "Epoch 179\n",
      "train_loss = 1.8100, val_loss = 1.7917\n",
      "Epoch 180\n",
      "train_loss = 1.7842, val_loss = 1.7949\n",
      "Epoch 181\n",
      "train_loss = 1.7775, val_loss = 1.7926\n",
      "Epoch 182\n",
      "train_loss = 1.7934, val_loss = 1.7925\n",
      "Epoch 183\n",
      "train_loss = 1.7620, val_loss = 1.7931\n",
      "Epoch 184\n",
      "train_loss = 1.8084, val_loss = 1.7931\n",
      "Epoch 185\n",
      "train_loss = 1.7793, val_loss = 1.7944\n",
      "Epoch 186\n",
      "train_loss = 1.8265, val_loss = 1.7940\n",
      "Epoch 187\n",
      "train_loss = 1.8247, val_loss = 1.7940\n",
      "Epoch 188\n",
      "train_loss = 1.7859, val_loss = 1.7931\n",
      "Epoch 189\n",
      "train_loss = 1.7565, val_loss = 1.7944\n",
      "Epoch 190\n",
      "train_loss = 1.8045, val_loss = 1.7920\n",
      "Epoch 191\n",
      "train_loss = 1.7743, val_loss = 1.7919\n",
      "Epoch 192\n",
      "train_loss = 1.8072, val_loss = 1.7942\n",
      "Epoch 193\n",
      "train_loss = 1.8039, val_loss = 1.7940\n",
      "Epoch 194\n",
      "train_loss = 1.7786, val_loss = 1.7933\n",
      "Epoch 195\n",
      "train_loss = 1.7795, val_loss = 1.7943\n",
      "Epoch 196\n",
      "train_loss = 1.8060, val_loss = 1.7929\n",
      "Epoch 197\n",
      "train_loss = 1.7902, val_loss = 1.7934\n",
      "Epoch 198\n",
      "train_loss = 1.7782, val_loss = 1.7933\n",
      "Epoch 199\n",
      "train_loss = 1.7852, val_loss = 1.7939\n",
      "Epoch 200\n",
      "train_loss = 1.8264, val_loss = 1.7940\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMNetwork(40, 100, 10, NUM_CLASSES)\n",
    "training_loop(lstm, train_loader, val_loader, epochs=200, is_seq=True, learning_rate=LEARNING_RATE, path=\"models/lstmseq\", weights=WEIGHTS, min_epoch=200)\n",
    "torch.save(lstm.state_dict(), \"models/lstmseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.7578\n",
      "accuracy = 0.2540\n",
      "f1 = 0.2442\n",
      "[[0.30749682 0.28314239 0.25454545 0.30735931 0.24782609 0.32258065]\n",
      " [0.33036849 0.33224223 0.43636364 0.36363636 0.40869565 0.19354839]\n",
      " [0.07115629 0.09328969 0.06363636 0.07792208 0.0826087  0.06451613]\n",
      " [0.14358323 0.14075286 0.11818182 0.12554113 0.12608696 0.16129032]\n",
      " [0.11435832 0.11129296 0.10909091 0.09090909 0.11304348 0.22580645]\n",
      " [0.03303685 0.03927987 0.01818182 0.03463203 0.02173913 0.03225806]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=lstm, val_dl=test_loader, is_seq=True)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CharTokenDataset(X_train, Y_train, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_data = CharTokenDataset(X_val, Y_val, tokenizer=None, max_seq_length=max_toks, dtype = torch.int32)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Batch size is hard coded to 1 for accuracy purposes. \n",
    "test_data = CharTokenDataset(X_test, Y_test, tokenizer=None, max_seq_length=max_toks, dtype=torch.int32)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1572589260.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    training_loop(transformer, train_loader, is_seq=True val_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE)\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerEncoder(max_toks, NUM_CLASSES, 10, 5, 4, ff=10, dropout=0.1)\n",
    "training_loop(transformer, train_loader,val_loader,  is_seq=True,  epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
    "torch.save(transformer.state_dict(), \"models/xformerseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.8737\n",
      "accuracy = 0.2015\n",
      "f1 = 0.1941\n",
      "[[0.29241877 0.29084381 0.275      0.42268041 0.2800852  0.1       ]\n",
      " [0.36823105 0.35008977 0.34166667 0.37113402 0.33865815 0.3       ]\n",
      " [0.09025271 0.06642729 0.08333333 0.07216495 0.08306709 0.2       ]\n",
      " [0.12635379 0.13105925 0.14166667 0.05154639 0.15228967 0.2       ]\n",
      " [0.09386282 0.11131059 0.125      0.07216495 0.11927583 0.2       ]\n",
      " [0.02888087 0.0502693  0.03333333 0.01030928 0.02662407 0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _, _, cmat = evaluate(model=transformer, val_dl=test_loader, is_seq=True)\n",
    "print(cmat)\n",
    "plt.matshow(cmat)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
